{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0565e31e",
   "metadata": {},
   "source": [
    "# <h1 style='font-size:2.2rem;color:orange;'>Stock Markets Sensitivity to Social vs. News Media Sentiment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e391cfd4",
   "metadata": {},
   "source": [
    "## 1. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install yfinance\n",
    "#pip install snscrape\n",
    "#pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5fba3e",
   "metadata": {},
   "source": [
    "## 2. Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bs4 as bs\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import time\n",
    "import concurrent.futures\n",
    "import re\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import yfinance as yf\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import string\n",
    "import itertools\n",
    "from segtok.segmenter import split_single\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import fastparquet\n",
    "\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "from segtok.segmenter import split_single\n",
    "from afinn import Afinn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import statsmodels.api as sm # statistical models including regression\n",
    "import scipy as sp # scientific calculation toolkit\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424bfe38",
   "metadata": {},
   "source": [
    "## 3. Download datasets | Stock Data | News Data | Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf58f7bd",
   "metadata": {},
   "source": [
    "### 3.1 Scrap Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list of selected stocks\n",
    "tickers= ['AAPL', 'MSFT', 'TSLA', 'AMZN', 'ATVI', 'NVDA', 'FB', 'UBER', 'V', 'MA', 'AVGO', 'CSCO', 'ADBE', 'CRM', 'AMD', 'INTC', 'NFLX']\n",
    "\n",
    "for ticker in tickers:\n",
    "    # Get the daily data for each stock from Sep 2021 to Feb 2022\n",
    "    data = yf.download(ticker,'2021-09-01','2022-03-01')\n",
    "    data['Ticker'] = ticker\n",
    "    # Output to csv\n",
    "    data.to_csv('Price_'+ str(ticker) + '.csv')\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "    # Get the hourly data for each stock from Sep 2021 to Feb 2022\n",
    "    data = yf.download(ticker,'2021-09-01','2022-03-01',interval=\"60m\")\n",
    "    data['Ticker'] = ticker\n",
    "    # Output to csv\n",
    "    data.to_csv('Hourly_Price_'+ str(ticker) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f5813e",
   "metadata": {},
   "source": [
    "### 3.2 Scrap News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up function to scrape news content from the news links\n",
    "def linkScraper(newsLinks):\n",
    "    \n",
    "    # Try to get the HTML elements using bs4\n",
    "    # If attempt is successful, append HTML elements to lists; If not, append nan to lists\n",
    "    try:\n",
    "        linkResp = requests.get(newsLinks)\n",
    "        linkSoup = bs.BeautifulSoup(linkResp.text, 'lxml')\n",
    "        \n",
    "    except:\n",
    "        print(newsLinks) \n",
    "\n",
    "    # Get url\n",
    "    try:\n",
    "        url.append(linkSoup.find('meta',{\"property\":\"og:url\"}).get('content'))\n",
    "    except:\n",
    "        url.append(np.nan)\n",
    "\n",
    "    # Get title\n",
    "    try:\n",
    "        title.append(linkSoup.find('h1',{\"class\":\"text__text__1FZLe text__dark-grey__3Ml43 text__medium__1kbOh text__heading_2__1K_hh heading__base__2T28j heading__heading_2__3Fcw5\"}).text)\n",
    "    except:\n",
    "        title.append(np.nan)\n",
    "\n",
    "    # Get date\n",
    "    try:        \n",
    "        date.append(linkSoup.find('span',{\"class\":\"date-line__date__23Ge-\"}).text + ' ' + linkSoup.findAll('span',{\"class\":\"date-line__date__23Ge-\"})[1].text)\n",
    "    except:\n",
    "        date.append(np.nan)\n",
    "\n",
    "    # Get author\n",
    "    try:\n",
    "        author.append(linkSoup.find('a',{\"class\":\"author-name__author__1gx5k\"}).text)\n",
    "    except:\n",
    "        author.append(np.nan)\n",
    "\n",
    "    # Get content\n",
    "    try:\n",
    "        content.append(linkSoup.find('div',{\"class\":\"article-body__content__3VtU3 paywall-article\"}).get_text(separator=' '))\n",
    "    except:\n",
    "        content.append(np.nan)\n",
    "    \n",
    "\n",
    "# Set up function to scrape all news links\n",
    "def newScraper():\n",
    "    # Initialize targeted stocks symbols\n",
    "    symbols = ['Amazon', 'Apple', 'Microsoft', 'Tesla', 'Blizzard', 'Nvidia', 'Facebook',\n",
    "               'Uber', 'Mastercard', 'AMD', 'Intel', 'Netflix']\n",
    "    \n",
    "    global news, stock, url, title, date, author, content\n",
    "    stock = []\n",
    "    url = []\n",
    "    title = []   \n",
    "    date = []\n",
    "    author = []  \n",
    "    content = [] \n",
    "    \n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "    \n",
    "    # Set up for loop to go through each stock\n",
    "    for symbol in symbols: \n",
    "        searchFormat = 'https://www.reuters.com/site-search/?query={}&offset={}&sort=newest&date=past_year'  \n",
    "        newsLinks = []\n",
    "\n",
    "        # Set up for loop to go through each page for each stock\n",
    "        for i in range(1,180):\n",
    "            try: \n",
    "                driver.get(searchFormat.format(symbol, i*10-10))\n",
    "                driver.implicitly_wait(3)\n",
    "                time.sleep(1) \n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            # Set up for loop to get each news for each page\n",
    "            for attempt in range(3):\n",
    "                try: \n",
    "\n",
    "                    # Obtain the web links for each news in that page\n",
    "                    elems = driver.find_elements_by_css_selector(\".search-results__item__2oqiX [href]\")\n",
    "                    if elems != []:\n",
    "                        for elem in elems:\n",
    "                            # Append the news links into a list\n",
    "                            newsLinks.append(elem.get_attribute('href'))\n",
    "\n",
    "                    else:\n",
    "                        print('no elements, go to next stock')\n",
    "                        break \n",
    "                    \n",
    "                except: \n",
    "                    print ('webpage error, retrying again')\n",
    "                    continue\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            break\n",
    "    \n",
    " \n",
    "        #Delete duplicates \n",
    "        newsLinks = list(set(newsLinks))\n",
    "\n",
    "        # Use concurrency to get the web elements for each scraped web link\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor: \n",
    "            executor.map(linkScraper, newsLinks)\n",
    "        stock.extend([symbol] * len(newsLinks))\n",
    "        \n",
    "\n",
    "        # Verify data collection completion\n",
    "        print(str(symbol) + \" stock length is : \" + str(len(stock)))\n",
    "        print(str(symbol) + \" url length is : \" + str(len(url)))\n",
    "        print(str(symbol) + \" title length is : \" + str(len(title)))\n",
    "        print(str(symbol) + \" date length is : \" + str(len(date)))\n",
    "        print(str(symbol) + \" author length is : \" + str(len(author)))\n",
    "        print(str(symbol) + \" content length is : \" + str(len(content)))\n",
    "    \n",
    "    # Output dataframe\n",
    "    news = pd.DataFrame({'Stock': stock, 'Date':date, 'Title': title, 'Author': author, 'Content':content, 'Url':url})  \n",
    "    \n",
    "    return (news)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b77d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>02/07/2021 21:31:00</td>\n",
       "      <td>AMD directors dodge shareholder derivative sui...</td>\n",
       "      <td>Jody Godoy</td>\n",
       "      <td>Summary Related documents Shareholder showed n...</td>\n",
       "      <td>https://www.reuters.com/legal/litigation/amd-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>27/04/2021 20:27:00</td>\n",
       "      <td>AMD lifts revenue forecast, CEO says supply ch...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>April 27 (Reuters) - Advanced Micro Devices In...</td>\n",
       "      <td>https://www.reuters.com/technology/amd-lifts-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>25/05/2021 13:00:00</td>\n",
       "      <td>Oracle launches Arm-based cloud computing serv...</td>\n",
       "      <td>Stephen Nellis</td>\n",
       "      <td>May 25 (Reuters) - Oracle Corp  (ORCL.N)  on T...</td>\n",
       "      <td>https://www.reuters.com/technology/oracle-laun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>29/11/2021 20:18:00</td>\n",
       "      <td>Wall Street regains some ground after virus pu...</td>\n",
       "      <td>Ambar Warrick</td>\n",
       "      <td>Summary Companies (Updates prices, adds commen...</td>\n",
       "      <td>https://www.reuters.com/markets/europe/wall-st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>21/09/2021 06:02:00</td>\n",
       "      <td>Novartis buys gene therapy firm Arctos Medical...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>ZURICH, Sept 21 (Reuters) - Swiss drugmaker No...</td>\n",
       "      <td>https://www.reuters.com/business/healthcare-ph...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker Stock                 Date  \\\n",
       "0    AMD   AMD  02/07/2021 21:31:00   \n",
       "1    AMD   AMD  27/04/2021 20:27:00   \n",
       "2    AMD   AMD  25/05/2021 13:00:00   \n",
       "3    AMD   AMD  29/11/2021 20:18:00   \n",
       "4    AMD   AMD  21/09/2021 06:02:00   \n",
       "\n",
       "                                               Title          Author  \\\n",
       "0  AMD directors dodge shareholder derivative sui...      Jody Godoy   \n",
       "1  AMD lifts revenue forecast, CEO says supply ch...         Reuters   \n",
       "2  Oracle launches Arm-based cloud computing serv...  Stephen Nellis   \n",
       "3  Wall Street regains some ground after virus pu...   Ambar Warrick   \n",
       "4  Novartis buys gene therapy firm Arctos Medical...         Reuters   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Summary Related documents Shareholder showed n...   \n",
       "1  April 27 (Reuters) - Advanced Micro Devices In...   \n",
       "2  May 25 (Reuters) - Oracle Corp  (ORCL.N)  on T...   \n",
       "3  Summary Companies (Updates prices, adds commen...   \n",
       "4  ZURICH, Sept 21 (Reuters) - Swiss drugmaker No...   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.reuters.com/legal/litigation/amd-d...  \n",
       "1  https://www.reuters.com/technology/amd-lifts-a...  \n",
       "2  https://www.reuters.com/technology/oracle-laun...  \n",
       "3  https://www.reuters.com/markets/europe/wall-st...  \n",
       "4  https://www.reuters.com/business/healthcare-ph...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6edeab6",
   "metadata": {},
   "source": [
    "### 3.3 Scrap Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['AMZN', 'AAPL', 'MSFT', 'TSLA', 'ATVI', 'NVDA', 'FB', 'UBER', 'MA', 'AMD', 'INTC', 'NFLX']\n",
    "for i in tickers:\n",
    "    # Define search term as #ticker and $ticker\n",
    "    search_term = '#{ticker} ${ticker}'.format(ticker = i)\n",
    "\n",
    "    # Set date range to be Sep 2021 to Feb 2022\n",
    "    snscrape_code = \"snscrape --jsonl --since 2021-09-01 twitter-search \\\"{x} until:2022-03-01\\\" > {ticker}_tweets.json\".format(x = search_term, ticker = i)\n",
    "    \n",
    "    # Using OS library to call CLI commands in Python\n",
    "    os.system(snscrape_code)\n",
    "\n",
    "    # Read the json file generated from the CLI commands above and create a pandas dataframe\n",
    "    read_path = '{ticker}_tweets.json'.format(ticker = i)\n",
    "    raw_tweets = pd.read_json(read_path, lines=True)\n",
    "\n",
    "    # Filter English tweets\n",
    "    raw_tweets = raw_tweets[raw_tweets.lang == 'en']\n",
    "    raw_tweets = raw_tweets.rename(columns={'id': 'tweet_id'})\n",
    "    \n",
    "    # Filter useful columns\n",
    "    raw_tweets = raw_tweets[['date','tweet_id','content','user','replyCount','retweetCount','likeCount','quoteCount','hashtags']]\n",
    "    \n",
    "    # Fetch user column dictionary data\n",
    "    df = pd.concat([raw_tweets.drop(['user'], axis=1), raw_tweets['user'].apply(pd.Series)], axis=1)\n",
    "    df = df[['date','tweet_id','content','replyCount','retweetCount','likeCount','quoteCount', 'verified','followersCount', 'friendsCount', 'listedCount', 'mediaCount']]\n",
    "    df['ticker'] = i\n",
    "\n",
    "    # Remove duplicate tweets to avoid bot tweets\n",
    "    df = df.drop_duplicates(subset=['content'], keep='first')\n",
    "    \n",
    "    # Output to csv\n",
    "    df.to_csv(os.path.join('tweet_{ticker}.csv'.format(ticker = i)), index=False)\n",
    "    print('~~ Finished outputting: ' + 'tweet_{ticker}.csv'.format(ticker = i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c819a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>content</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>verified</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>listedCount</th>\n",
       "      <th>mediaCount</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-28 07:00:22+00:00</th>\n",
       "      <td>1498191328072675331</td>\n",
       "      <td>$NFLX Weekly. #NFLX 2 hammer candlesticks (one...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>18590</td>\n",
       "      <td>494</td>\n",
       "      <td>520</td>\n",
       "      <td>8381</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-24 12:10:07+00:00</th>\n",
       "      <td>1496819727708135428</td>\n",
       "      <td>$NFLX whoops #NFLX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>786</td>\n",
       "      <td>58</td>\n",
       "      <td>25</td>\n",
       "      <td>3007</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-23 15:15:28+00:00</th>\n",
       "      <td>1496503985951641605</td>\n",
       "      <td>$nflx #nflx + 48% gain already this AM #tradin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-23 00:01:18+00:00</th>\n",
       "      <td>1496273928502841344</td>\n",
       "      <td>#Netflix $NFLX #NFLX What a horrendous looking...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>524</td>\n",
       "      <td>1054</td>\n",
       "      <td>6</td>\n",
       "      <td>1328</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-22 19:25:44+00:00</th>\n",
       "      <td>1496204581268721664</td>\n",
       "      <td>$NFLX - #NFLX chart on</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1842</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>10933</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      tweet_id  \\\n",
       "date                                             \n",
       "2022-02-28 07:00:22+00:00  1498191328072675331   \n",
       "2022-02-24 12:10:07+00:00  1496819727708135428   \n",
       "2022-02-23 15:15:28+00:00  1496503985951641605   \n",
       "2022-02-23 00:01:18+00:00  1496273928502841344   \n",
       "2022-02-22 19:25:44+00:00  1496204581268721664   \n",
       "\n",
       "                                                                     content  \\\n",
       "date                                                                           \n",
       "2022-02-28 07:00:22+00:00  $NFLX Weekly. #NFLX 2 hammer candlesticks (one...   \n",
       "2022-02-24 12:10:07+00:00                                $NFLX whoops #NFLX    \n",
       "2022-02-23 15:15:28+00:00  $nflx #nflx + 48% gain already this AM #tradin...   \n",
       "2022-02-23 00:01:18+00:00  #Netflix $NFLX #NFLX What a horrendous looking...   \n",
       "2022-02-22 19:25:44+00:00                            $NFLX - #NFLX chart on    \n",
       "\n",
       "                           replyCount  retweetCount  likeCount  quoteCount  \\\n",
       "date                                                                         \n",
       "2022-02-28 07:00:22+00:00           0             0          4           0   \n",
       "2022-02-24 12:10:07+00:00           0             0          0           0   \n",
       "2022-02-23 15:15:28+00:00           0             0          1           0   \n",
       "2022-02-23 00:01:18+00:00           0             0          0           0   \n",
       "2022-02-22 19:25:44+00:00           0             0          0           0   \n",
       "\n",
       "                           verified  followersCount  friendsCount  \\\n",
       "date                                                                \n",
       "2022-02-28 07:00:22+00:00     False           18590           494   \n",
       "2022-02-24 12:10:07+00:00     False             786            58   \n",
       "2022-02-23 15:15:28+00:00     False              20            37   \n",
       "2022-02-23 00:01:18+00:00     False             524          1054   \n",
       "2022-02-22 19:25:44+00:00     False            1842             0   \n",
       "\n",
       "                           listedCount  mediaCount ticker  \n",
       "date                                                       \n",
       "2022-02-28 07:00:22+00:00          520        8381   NFLX  \n",
       "2022-02-24 12:10:07+00:00           25        3007   NFLX  \n",
       "2022-02-23 15:15:28+00:00            0          39   NFLX  \n",
       "2022-02-23 00:01:18+00:00            6        1328   NFLX  \n",
       "2022-02-22 19:25:44+00:00           34       10933   NFLX  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d098a5f0",
   "metadata": {},
   "source": [
    "## 4. Data Pre-processing | Stock Data | News Data | Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9987393e",
   "metadata": {},
   "source": [
    "### 4.1 News Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04390fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nan\n",
    "news = news.dropna()\n",
    "news['Content_Clean'] = news.Content\n",
    "news['Content_Clean'] = [i.replace('Register now for FREE unlimited access to Reuters.com Register ', '')\n",
    "            .replace(' Our Standards:  The Thomson Reuters Trust Principles.', '') for i in news.Content_Clean]\n",
    "\n",
    "# Convert to lowercase\n",
    "news.Content_Clean = news.Content_Clean.map(lambda x: x.lower())\n",
    "\n",
    "# Remove symbols\n",
    "news.Content_Clean = news.Content_Clean.map(lambda x: re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ', x))\n",
    "news.Content_Clean = news.Content_Clean.map(lambda x: re.sub('@[^\\s]+',' ', x))\n",
    "news.Content_Clean = news.Content_Clean.map(lambda x: re.sub('[,.\\'\"!+?\\-=)(*><&/;:$%]', ' ', x))\n",
    "news.Content_Clean = news.Content_Clean.map(lambda x: re.sub('[\\s]+', ' ', x))\n",
    "\n",
    "\n",
    "# Insert ticker column for stocks\n",
    "ticker = ['AMZN', 'AAPL', 'MSFT', 'TSLA', 'ATVI', 'NVDA', 'FB', 'UBER', 'MA', 'AMD', 'INTC', 'NFLX']\n",
    "stockDict = dict(zip(news.Stock.unique(), ticker))\n",
    "tickerList = list(news.Stock.map(stockDict))\n",
    "news.insert(loc = 0, column = 'Ticker', value = tickerList)\n",
    "\n",
    "\n",
    "# Convert date column to datetime\n",
    "news.Date = pd.to_datetime(news['Date'])\n",
    "news.Date = news.Date.dt.strftime('%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "\n",
    "# Tokenize news\n",
    "def newsToken(i):\n",
    "    for i in news.Content_Clean: \n",
    "         yield(gensim.utils.simple_preprocess(str(i), deacc=True)) \n",
    " \n",
    "    \n",
    "# Remove stopwords\n",
    "def newsStopword(content):   \n",
    "    stopWords = stopwords.words('english') \n",
    "    # Customize stop words\n",
    "    stopWords.extend(['reuters', 'january', 'february', 'march', 'april', 'may', 'june', \n",
    "                      'july', 'august', 'september', 'october', 'november', 'december', \n",
    "                      'london', 'summary', 'new york','bengaluru', 'america'])\n",
    "    keepWords = ['up','down','against', 'above','below','off','over','further','no','not','only']\n",
    "    stopWords = list(set(stopWords) - set(keepWords))\n",
    "    return [[i for i in simple_preprocess(str(doc)) \n",
    "             if i not in stopWords and len(i) >=1 ] for doc in content] \n",
    "\n",
    "    \n",
    "# Lemmatize tokens\n",
    "def newsLemmatization(content, allowed_postags=['NOUN', 'PROPN', 'VERB', 'ADP', 'ADJ']):  \n",
    "    # Use spaCy library and load English package\n",
    "    nlp = spacy.load(\"en_core_web_sm\")  \n",
    "    texts_out = []\n",
    "    # Perform the function on each news content\n",
    "    for i in content: \n",
    "        # Join the words together for lemmatization analysis\n",
    "        doc = nlp(\" \".join(i)) \n",
    "        # Get the lemmatized version for each word\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags]) \n",
    "    return texts_out\n",
    "\n",
    "\n",
    "# Execute step by step\n",
    "matrix1 = list(newsToken(news.Content_Clean))  \n",
    "matrix2 = newsLemmatization(matrix1)\n",
    "matrix3 = newsStopword(matrix2) \n",
    "\n",
    "# Insert columns for tokenized content\n",
    "news.insert(loc = 7 , column = 'Content_Clean_Token', value = matrix3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7ca17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Clean</th>\n",
       "      <th>Content_Clean_Token</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>02/07/2021 21:31:00</td>\n",
       "      <td>AMD directors dodge shareholder derivative sui...</td>\n",
       "      <td>Jody Godoy</td>\n",
       "      <td>Summary Related documents Shareholder showed n...</td>\n",
       "      <td>related document shareholder show basis skip d...</td>\n",
       "      <td>['related' 'document' 'shareholder' 'show' 'ba...</td>\n",
       "      <td>https://www.reuters.com/legal/litigation/amd-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>27/04/2021 20:27:00</td>\n",
       "      <td>AMD lifts revenue forecast, CEO says supply ch...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>April 27 (Reuters) - Advanced Micro Devices In...</td>\n",
       "      <td>advance micro devices inc amd raise annual rev...</td>\n",
       "      <td>['advance' 'micro' 'devices' 'inc' 'amd' 'rais...</td>\n",
       "      <td>https://www.reuters.com/technology/amd-lifts-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>25/05/2021 13:00:00</td>\n",
       "      <td>Oracle launches Arm-based cloud computing serv...</td>\n",
       "      <td>Stephen Nellis</td>\n",
       "      <td>May 25 (Reuters) - Oracle Corp  (ORCL.N)  on T...</td>\n",
       "      <td>oracle corp orcl tuesday launch cloud computin...</td>\n",
       "      <td>['oracle' 'corp' 'orcl' 'tuesday' 'launch' 'cl...</td>\n",
       "      <td>https://www.reuters.com/technology/oracle-laun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>29/11/2021 20:18:00</td>\n",
       "      <td>Wall Street regains some ground after virus pu...</td>\n",
       "      <td>Ambar Warrick</td>\n",
       "      <td>Summary Companies (Updates prices, adds commen...</td>\n",
       "      <td>company update price add commentary change byl...</td>\n",
       "      <td>['company' 'update' 'price' 'add' 'commentary'...</td>\n",
       "      <td>https://www.reuters.com/markets/europe/wall-st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>21/09/2021 06:02:00</td>\n",
       "      <td>Novartis buys gene therapy firm Arctos Medical...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>ZURICH, Sept 21 (Reuters) - Swiss drugmaker No...</td>\n",
       "      <td>zurich sept swiss drugmaker novartis novn say ...</td>\n",
       "      <td>['zurich' 'sept' 'swiss' 'drugmaker' 'novartis...</td>\n",
       "      <td>https://www.reuters.com/business/healthcare-ph...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker Stock                 Date  \\\n",
       "0    AMD   AMD  02/07/2021 21:31:00   \n",
       "1    AMD   AMD  27/04/2021 20:27:00   \n",
       "2    AMD   AMD  25/05/2021 13:00:00   \n",
       "3    AMD   AMD  29/11/2021 20:18:00   \n",
       "4    AMD   AMD  21/09/2021 06:02:00   \n",
       "\n",
       "                                               Title          Author  \\\n",
       "0  AMD directors dodge shareholder derivative sui...      Jody Godoy   \n",
       "1  AMD lifts revenue forecast, CEO says supply ch...         Reuters   \n",
       "2  Oracle launches Arm-based cloud computing serv...  Stephen Nellis   \n",
       "3  Wall Street regains some ground after virus pu...   Ambar Warrick   \n",
       "4  Novartis buys gene therapy firm Arctos Medical...         Reuters   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Summary Related documents Shareholder showed n...   \n",
       "1  April 27 (Reuters) - Advanced Micro Devices In...   \n",
       "2  May 25 (Reuters) - Oracle Corp  (ORCL.N)  on T...   \n",
       "3  Summary Companies (Updates prices, adds commen...   \n",
       "4  ZURICH, Sept 21 (Reuters) - Swiss drugmaker No...   \n",
       "\n",
       "                                       Content_Clean  \\\n",
       "0  related document shareholder show basis skip d...   \n",
       "1  advance micro devices inc amd raise annual rev...   \n",
       "2  oracle corp orcl tuesday launch cloud computin...   \n",
       "3  company update price add commentary change byl...   \n",
       "4  zurich sept swiss drugmaker novartis novn say ...   \n",
       "\n",
       "                                 Content_Clean_Token  \\\n",
       "0  ['related' 'document' 'shareholder' 'show' 'ba...   \n",
       "1  ['advance' 'micro' 'devices' 'inc' 'amd' 'rais...   \n",
       "2  ['oracle' 'corp' 'orcl' 'tuesday' 'launch' 'cl...   \n",
       "3  ['company' 'update' 'price' 'add' 'commentary'...   \n",
       "4  ['zurich' 'sept' 'swiss' 'drugmaker' 'novartis...   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.reuters.com/legal/litigation/amd-d...  \n",
       "1  https://www.reuters.com/technology/amd-lifts-a...  \n",
       "2  https://www.reuters.com/technology/oracle-laun...  \n",
       "3  https://www.reuters.com/markets/europe/wall-st...  \n",
       "4  https://www.reuters.com/business/healthcare-ph...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ca4e01",
   "metadata": {},
   "source": [
    "### 4.2 Tweets Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68597d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "# Merge all tweets csv within a given path\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    df1 = pd.read_csv(file)\n",
    "    df = pd.concat([df, df1])\n",
    "    \n",
    "# Convert date column to datetime\n",
    "df.date = pd.to_datetime(df['date'])\n",
    "df.date = df.date.dt.strftime('%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "\n",
    "def _1_TextprocessTweet(tweet):\n",
    "    #C onvert to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # Remove www.* or https?://*\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',tweet)\n",
    "    # Remove @username \n",
    "    tweet = re.sub('@[^\\s]+',' ',tweet)\n",
    "    # Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    # Remove newlines\n",
    "    tweet = tweet.strip('\\n')\n",
    "\n",
    "    # Remove all username mentions, hashtags and ticker tags\n",
    "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)|(\\$[A-Za-z0-9]+)\", \" \", tweet).split())\n",
    "    \n",
    "    # Replace emoji with text\n",
    "    tweet = emoji.demojize(tweet)\n",
    "    tweet = tweet.replace(\":\",\" \")\n",
    "    tweet = ' '.join(tweet.split())\n",
    "    tweet = tweet.replace('_',\" \")\n",
    "    return tweet\n",
    "\n",
    "\n",
    "# Tokenize\n",
    "def _2_Tokenize_Stopword(tweet):  \n",
    "\n",
    "    # Remove punctuation\n",
    "    tweet = tweet.replace('\\'','')\n",
    "    tweet = re.sub('[%s]' % re.escape(string.punctuation), ' ', tweet) \n",
    "\n",
    "    # Perform word_tokenize\n",
    "    tokens = [w for w in word_tokenize(tweet) if w.isalpha()] \n",
    "\n",
    "    # Customize and remove stop words\n",
    "    stopWords = stopwords.words('english') \n",
    "    keepWords = ['up','down','against', 'above','below','off','over','further','no','not','only']\n",
    "    stopWords = list(set(stopWords) - set(keepWords))\n",
    "    stopWords.extend(['amzn', 'aapl', 'msft', 'tsla', 'atvi', 'nvda', 'fb', 'uber', 'ma', 'amd', 'intc', 'nflx'])\n",
    "\n",
    "    tweet = [t for t in tokens if t not in stopWords]\n",
    "    return tweet\n",
    "\n",
    "\n",
    "# Lemmatize tokens\n",
    "def _3_Lemmatization(tweet, allowed_postags=['NOUN', 'PROPN', 'VERB', 'ADP','ADJ']):  \n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(\" \".join(tweet))\n",
    "    tweet = [token.lemma_ for token in doc if token.pos_ in allowed_postags]\n",
    "    return tweet\n",
    "\n",
    "\n",
    "# Populate various processed columns\n",
    "df['content_clean'] = df['content'].apply(_1_TextprocessTweet)\n",
    "df['content_tokenized'] = df['content_clean'].apply(_2_Tokenize_Stopword)\n",
    "\n",
    "\n",
    "# Use concurrency to speed up the lemmatization function\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor: \n",
    "    df['content_lemmatized'] = list(executor.map(_3_Lemmatization, df['content_tokenized']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d829447c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>content</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>verified</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>listedCount</th>\n",
       "      <th>mediaCount</th>\n",
       "      <th>ticker</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>content_tokenized</th>\n",
       "      <th>content_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28/02/2022 22:39:16</td>\n",
       "      <td>1498427612665987078</td>\n",
       "      <td>$SPY #SPY #QQQ $QQQ $UVXY #UVXY $AMC #AMC $AAP...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>279</td>\n",
       "      <td>1026</td>\n",
       "      <td>4</td>\n",
       "      <td>833</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>final liquidity pump underway. this is it. the...</td>\n",
       "      <td>['final', 'liquidity', 'pump', 'underway', 'su...</td>\n",
       "      <td>['final', 'liquidity', 'pump', 'underway', 'su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28/02/2022 21:42:08</td>\n",
       "      <td>1498413233698443272</td>\n",
       "      <td>$AAPL held Premarket high for a bit in morning...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>258</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>held premarket high for a bit in morning befor...</td>\n",
       "      <td>['held', 'premarket', 'high', 'bit', 'morning'...</td>\n",
       "      <td>['hold', 'premarket', 'high', 'bit', 'morning'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28/02/2022 21:30:00</td>\n",
       "      <td>1498410179972399105</td>\n",
       "      <td>$AAPL closed today at $165.12. If you bought 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>closed today at .12. if you bought 1 share of ...</td>\n",
       "      <td>['closed', 'today', 'bought', 'share', 'closin...</td>\n",
       "      <td>['close', 'today', 'buy', 'share', 'closing', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28/02/2022 10:28:15</td>\n",
       "      <td>1498243644431732743</td>\n",
       "      <td>$SPY #SPY #QQQ $QQQ $AMC #AMC $AAPL #AAPL $GME...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>279</td>\n",
       "      <td>1026</td>\n",
       "      <td>4</td>\n",
       "      <td>833</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>levels still valid and all levels will be rete...</td>\n",
       "      <td>['levels', 'still', 'valid', 'levels', 'retest...</td>\n",
       "      <td>['level', 'valid', 'level', 'reteste', 'up', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28/02/2022 04:57:58</td>\n",
       "      <td>1498160526311915520</td>\n",
       "      <td>$AAPL Weekly. #AAPL formed a hammer candlestic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>18591</td>\n",
       "      <td>494</td>\n",
       "      <td>520</td>\n",
       "      <td>8381</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>weekly. formed a hammer candlestick last week,...</td>\n",
       "      <td>['weekly', 'formed', 'hammer', 'candlestick', ...</td>\n",
       "      <td>['weekly', 'form', 'hammer', 'candlestick', 'l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date             tweet_id  \\\n",
       "0  28/02/2022 22:39:16  1498427612665987078   \n",
       "1  28/02/2022 21:42:08  1498413233698443272   \n",
       "2  28/02/2022 21:30:00  1498410179972399105   \n",
       "3  28/02/2022 10:28:15  1498243644431732743   \n",
       "4  28/02/2022 04:57:58  1498160526311915520   \n",
       "\n",
       "                                             content  replyCount  \\\n",
       "0  $SPY #SPY #QQQ $QQQ $UVXY #UVXY $AMC #AMC $AAP...           0   \n",
       "1  $AAPL held Premarket high for a bit in morning...           0   \n",
       "2  $AAPL closed today at $165.12. If you bought 1...           0   \n",
       "3  $SPY #SPY #QQQ $QQQ $AMC #AMC $AAPL #AAPL $GME...           0   \n",
       "4  $AAPL Weekly. #AAPL formed a hammer candlestic...           0   \n",
       "\n",
       "   retweetCount  likeCount  quoteCount  verified  followersCount  \\\n",
       "0             1          2           0     False             279   \n",
       "1             0          0           0     False              60   \n",
       "2             0          0           0     False              50   \n",
       "3             1          2           0     False             279   \n",
       "4             0         12           0     False           18591   \n",
       "\n",
       "   friendsCount  listedCount  mediaCount ticker  \\\n",
       "0          1026            4         833   AAPL   \n",
       "1           258            4          32   AAPL   \n",
       "2            11            0           1   AAPL   \n",
       "3          1026            4         833   AAPL   \n",
       "4           494          520        8381   AAPL   \n",
       "\n",
       "                                       content_clean  \\\n",
       "0  final liquidity pump underway. this is it. the...   \n",
       "1  held premarket high for a bit in morning befor...   \n",
       "2  closed today at .12. if you bought 1 share of ...   \n",
       "3  levels still valid and all levels will be rete...   \n",
       "4  weekly. formed a hammer candlestick last week,...   \n",
       "\n",
       "                                   content_tokenized  \\\n",
       "0  ['final', 'liquidity', 'pump', 'underway', 'su...   \n",
       "1  ['held', 'premarket', 'high', 'bit', 'morning'...   \n",
       "2  ['closed', 'today', 'bought', 'share', 'closin...   \n",
       "3  ['levels', 'still', 'valid', 'levels', 'retest...   \n",
       "4  ['weekly', 'formed', 'hammer', 'candlestick', ...   \n",
       "\n",
       "                                  content_lemmatized  \n",
       "0  ['final', 'liquidity', 'pump', 'underway', 'su...  \n",
       "1  ['hold', 'premarket', 'high', 'bit', 'morning'...  \n",
       "2  ['close', 'today', 'buy', 'share', 'closing', ...  \n",
       "3  ['level', 'valid', 'level', 'reteste', 'up', '...  \n",
       "4  ['weekly', 'form', 'hammer', 'candlestick', 'l...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca73b60",
   "metadata": {},
   "source": [
    "## 5. Sentiment Analysis | News Data | Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474a458",
   "metadata": {},
   "source": [
    "### 5.1 Library Flair (Using sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af9b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize by sentence since Flair is sentence-based\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "news = news.dropna()\n",
    "\n",
    "def flairClean(row):\n",
    "    # Clean some uselss sentences first for news\n",
    "    rows = row.replace('Register now for FREE unlimited access to Reuters.com Register ', '').replace(\n",
    "        ' Our Standards:  The Thomson Reuters Trust Principles.', '') \n",
    "\n",
    "    # Clean symbols\n",
    "    rows = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ', rows)\n",
    "    rows = re.sub('@[^\\s]+',' ', rows)\n",
    "    rows = re.sub('[\\'\"!+?=)(*><&/;:$%\\n]', ' ', rows)\n",
    "    rows = re.sub('[\\s]+', ' ', rows)\n",
    "    return rows\n",
    "\n",
    "# Split into sentences\n",
    "def sentence(paragraph):\n",
    "    sentences = [elm for elm in split_single(paragraph)]\n",
    "    return sentences\n",
    "\n",
    "# Clean empty string in the list, in case the sentence is empty\n",
    "def cleanEmpty(sentence):\n",
    "    \n",
    "    a = [x for x in sentence if x]\n",
    "    \n",
    "    return a\n",
    "\n",
    "\n",
    "# Generate sentiment score\n",
    "def flair(sentence):\n",
    "\n",
    "    # Initialize variables\n",
    "    poslen = 0\n",
    "    neglen = 0 \n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    \n",
    "    # Set up for loop to obtain the sentiment scores of each sentence\n",
    "    for i in sentence:\n",
    "        text = Sentence(i)\n",
    "        classifier.predict(text)\n",
    "               \n",
    "        value = text.labels[0].to_dict()['value'] \n",
    "        if value == 'POSITIVE':\n",
    "            pos += text.labels[0].to_dict()['confidence']\n",
    "            poslen += 1\n",
    "        else:\n",
    "            neg += -(text.labels[0].to_dict()['confidence'])\n",
    "            neglen += 1\n",
    "\n",
    "\n",
    "    # Standardize the sentiment scores between [1,-1]\n",
    "    # Calculate the compound sentiment score\n",
    "    if poslen == 0 and neglen == 0:\n",
    "        score = 0            \n",
    "    elif neglen == 0:\n",
    "        score = pos/poslen\n",
    "    elif poslen == 0:\n",
    "        score = neg/neglen\n",
    "    else:\n",
    "        score = (pos+neg)/(pos+abs(neg))\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "# Create new columns\n",
    "news['Sentiment_Flair'] = news['Content'].apply(flairClean).apply(sentence).apply(flair)\n",
    "\n",
    "try:\n",
    "    df['Sentiment_Flair'] = df['content_clean'].apply(flairClean).apply(sentence).apply(cleanEmpty).apply(flair)\n",
    "except:\n",
    "    df['Sentiment_Flair'] = df['content_lemmatized'].apply(flair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e0d61",
   "metadata": {},
   "source": [
    "### 5.2 Library Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355be17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Afinn function\n",
    "def afinn(text):\n",
    "\n",
    "    # Initialize values\n",
    "    afinn = Afinn(language = 'en') \n",
    "    poslen = 0\n",
    "    neglen = 0 \n",
    "    pos = 0\n",
    "    neg = 0\n",
    "\n",
    "    # Standardize the sentiment scores between [1,-1]\n",
    "    # Calculate the compound sentiment score\n",
    "    for i in text:\n",
    "        if afinn.score(i) > 0:\n",
    "            pos += afinn.score(i)\n",
    "            poslen += 1\n",
    "        elif afinn.score(i) < 0:\n",
    "            neg += afinn.score(i)\n",
    "            neglen += 1\n",
    "\n",
    "    if poslen == 0 and neglen == 0:\n",
    "        score = 0            \n",
    "    elif neglen == 0:\n",
    "        score = (pos/poslen)/5\n",
    "    elif poslen == 0:\n",
    "        score = (neg/neglen)/5\n",
    "    else:\n",
    "        score = (pos+neg)/(pos+abs(neg))\n",
    "    \n",
    "    return score\n",
    "    \n",
    "# Create new columns\n",
    "df['content_lemmatized'].apply(afinn)\n",
    "news['Content_Clean_Token'].apply(afinn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c5af45",
   "metadata": {},
   "source": [
    "### 5.3 Library Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6723c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Vader function\n",
    "def vader(text):\n",
    "\n",
    "    # Edit lexicon to assign sentiment score for special terms and emojis\n",
    "    new_words = {\n",
    "    'fire': 4.0,\n",
    "    'decreasing': -4.0,\n",
    "    'increasing': 4.0,\n",
    "    'decrease': -4.0,\n",
    "    'increase': 4.0,\n",
    "    'rocket':4.0,\n",
    "    'up':4.0,\n",
    "    'down':-4.0,\n",
    "    'bull':4.0,\n",
    "    'bear':-4.0\n",
    "    }\n",
    "\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Update lexicon\n",
    "    sia.lexicon.update(new_words)\n",
    "\n",
    "    # Initialize values\n",
    "    poslen = 0\n",
    "    neglen = 0 \n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    \n",
    "\n",
    "    # Standardize the sentiment scores between [1,-1]\n",
    "    # Calculate the compound sentiment score\n",
    "    for i in text:\n",
    "        if sia.polarity_scores(i)['compound'] > 0:\n",
    "            pos += sia.polarity_scores(i)['compound']\n",
    "            poslen += 1\n",
    "        elif sia.polarity_scores(i)['compound'] < 0:\n",
    "            neg += sia.polarity_scores(i)['compound']\n",
    "            neglen += 1\n",
    "                       \n",
    "    if poslen == 0 and neglen == 0:\n",
    "        score = 0            \n",
    "    elif neglen == 0:\n",
    "        score = (pos/poslen)\n",
    "    elif poslen == 0:\n",
    "        score = (neg/neglen)\n",
    "    else:\n",
    "        score = (pos+neg)/(pos+abs(neg))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffc946b",
   "metadata": {},
   "source": [
    "### 5.4 Library TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf766fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up TextBlob function\n",
    "def textblob(text):\n",
    "\n",
    "    # Initialize values\n",
    "    poslen = 0\n",
    "    neglen = 0 \n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    \n",
    "\n",
    "    # Standardize the sentiment scores between [1,-1]\n",
    "    # Calculate the compound sentiment score\n",
    "    for i in text:\n",
    "        if TextBlob(i).sentiment.polarity > 0:\n",
    "            pos += TextBlob(i).sentiment.polarity\n",
    "            poslen += 1\n",
    "        elif TextBlob(i).sentiment.polarity < 0:\n",
    "            neg += TextBlob(i).sentiment.polarity\n",
    "            neglen += 1\n",
    "\n",
    "    if poslen == 0 and neglen == 0:\n",
    "        score = 0            \n",
    "    elif neglen == 0:\n",
    "        score = (pos/poslen)\n",
    "    elif poslen == 0:\n",
    "        score = (neg/neglen)\n",
    "    else:\n",
    "        score = (pos+neg)/(pos+abs(neg))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295c765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Clean</th>\n",
       "      <th>Content_Clean_Token</th>\n",
       "      <th>Url</th>\n",
       "      <th>Sentiment_Flair</th>\n",
       "      <th>Sentiment_Afinn</th>\n",
       "      <th>Sentiment_Vader</th>\n",
       "      <th>Sentiment_TextBlob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>02/07/2021 21:31:00</td>\n",
       "      <td>AMD directors dodge shareholder derivative sui...</td>\n",
       "      <td>Jody Godoy</td>\n",
       "      <td>Summary Related documents Shareholder showed n...</td>\n",
       "      <td>related document shareholder show basis skip d...</td>\n",
       "      <td>['related' 'document' 'shareholder' 'show' 'ba...</td>\n",
       "      <td>https://www.reuters.com/legal/litigation/amd-d...</td>\n",
       "      <td>-0.600430</td>\n",
       "      <td>-0.780220</td>\n",
       "      <td>-0.593653</td>\n",
       "      <td>-0.656827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>27/04/2021 20:27:00</td>\n",
       "      <td>AMD lifts revenue forecast, CEO says supply ch...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>April 27 (Reuters) - Advanced Micro Devices In...</td>\n",
       "      <td>advance micro devices inc amd raise annual rev...</td>\n",
       "      <td>['advance' 'micro' 'devices' 'inc' 'amd' 'rais...</td>\n",
       "      <td>https://www.reuters.com/technology/amd-lifts-a...</td>\n",
       "      <td>0.370084</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.780044</td>\n",
       "      <td>0.589689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>25/05/2021 13:00:00</td>\n",
       "      <td>Oracle launches Arm-based cloud computing serv...</td>\n",
       "      <td>Stephen Nellis</td>\n",
       "      <td>May 25 (Reuters) - Oracle Corp  (ORCL.N)  on T...</td>\n",
       "      <td>oracle corp orcl tuesday launch cloud computin...</td>\n",
       "      <td>['oracle' 'corp' 'orcl' 'tuesday' 'launch' 'cl...</td>\n",
       "      <td>https://www.reuters.com/technology/oracle-laun...</td>\n",
       "      <td>0.436454</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>-0.524692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>29/11/2021 20:18:00</td>\n",
       "      <td>Wall Street regains some ground after virus pu...</td>\n",
       "      <td>Ambar Warrick</td>\n",
       "      <td>Summary Companies (Updates prices, adds commen...</td>\n",
       "      <td>company update price add commentary change byl...</td>\n",
       "      <td>['company' 'update' 'price' 'add' 'commentary'...</td>\n",
       "      <td>https://www.reuters.com/markets/europe/wall-st...</td>\n",
       "      <td>-0.482530</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.200357</td>\n",
       "      <td>0.235957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>21/09/2021 06:02:00</td>\n",
       "      <td>Novartis buys gene therapy firm Arctos Medical...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>ZURICH, Sept 21 (Reuters) - Swiss drugmaker No...</td>\n",
       "      <td>zurich sept swiss drugmaker novartis novn say ...</td>\n",
       "      <td>['zurich' 'sept' 'swiss' 'drugmaker' 'novartis...</td>\n",
       "      <td>https://www.reuters.com/business/healthcare-ph...</td>\n",
       "      <td>0.250985</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.408526</td>\n",
       "      <td>-0.215686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker Stock                 Date  \\\n",
       "0    AMD   AMD  02/07/2021 21:31:00   \n",
       "1    AMD   AMD  27/04/2021 20:27:00   \n",
       "2    AMD   AMD  25/05/2021 13:00:00   \n",
       "3    AMD   AMD  29/11/2021 20:18:00   \n",
       "4    AMD   AMD  21/09/2021 06:02:00   \n",
       "\n",
       "                                               Title          Author  \\\n",
       "0  AMD directors dodge shareholder derivative sui...      Jody Godoy   \n",
       "1  AMD lifts revenue forecast, CEO says supply ch...         Reuters   \n",
       "2  Oracle launches Arm-based cloud computing serv...  Stephen Nellis   \n",
       "3  Wall Street regains some ground after virus pu...   Ambar Warrick   \n",
       "4  Novartis buys gene therapy firm Arctos Medical...         Reuters   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Summary Related documents Shareholder showed n...   \n",
       "1  April 27 (Reuters) - Advanced Micro Devices In...   \n",
       "2  May 25 (Reuters) - Oracle Corp  (ORCL.N)  on T...   \n",
       "3  Summary Companies (Updates prices, adds commen...   \n",
       "4  ZURICH, Sept 21 (Reuters) - Swiss drugmaker No...   \n",
       "\n",
       "                                       Content_Clean  \\\n",
       "0  related document shareholder show basis skip d...   \n",
       "1  advance micro devices inc amd raise annual rev...   \n",
       "2  oracle corp orcl tuesday launch cloud computin...   \n",
       "3  company update price add commentary change byl...   \n",
       "4  zurich sept swiss drugmaker novartis novn say ...   \n",
       "\n",
       "                                 Content_Clean_Token  \\\n",
       "0  ['related' 'document' 'shareholder' 'show' 'ba...   \n",
       "1  ['advance' 'micro' 'devices' 'inc' 'amd' 'rais...   \n",
       "2  ['oracle' 'corp' 'orcl' 'tuesday' 'launch' 'cl...   \n",
       "3  ['company' 'update' 'price' 'add' 'commentary'...   \n",
       "4  ['zurich' 'sept' 'swiss' 'drugmaker' 'novartis...   \n",
       "\n",
       "                                                 Url  Sentiment_Flair  \\\n",
       "0  https://www.reuters.com/legal/litigation/amd-d...        -0.600430   \n",
       "1  https://www.reuters.com/technology/amd-lifts-a...         0.370084   \n",
       "2  https://www.reuters.com/technology/oracle-laun...         0.436454   \n",
       "3  https://www.reuters.com/markets/europe/wall-st...        -0.482530   \n",
       "4  https://www.reuters.com/business/healthcare-ph...         0.250985   \n",
       "\n",
       "   Sentiment_Afinn  Sentiment_Vader  Sentiment_TextBlob  \n",
       "0        -0.780220        -0.593653           -0.656827  \n",
       "1         0.705882         0.780044            0.589689  \n",
       "2         0.882353         0.281721           -0.524692  \n",
       "3         0.025641         0.200357            0.235957  \n",
       "4         0.047619         0.408526           -0.215686  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4f97a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>content</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>verified</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>listedCount</th>\n",
       "      <th>mediaCount</th>\n",
       "      <th>ticker</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>content_tokenized</th>\n",
       "      <th>content_lemmatized</th>\n",
       "      <th>Sentiment_Flair</th>\n",
       "      <th>Sentiment_Afinn</th>\n",
       "      <th>Sentiment_Vader</th>\n",
       "      <th>Sentiment_TextBlob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28/02/2022 22:39:16</td>\n",
       "      <td>1498427612665987078</td>\n",
       "      <td>$SPY #SPY #QQQ $QQQ $UVXY #UVXY $AMC #AMC $AAP...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>279</td>\n",
       "      <td>1026</td>\n",
       "      <td>4</td>\n",
       "      <td>833</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>final liquidity pump underway. this is it. the...</td>\n",
       "      <td>['final', 'liquidity', 'pump', 'underway', 'su...</td>\n",
       "      <td>['final', 'liquidity', 'pump', 'underway', 'su...</td>\n",
       "      <td>0.997430</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.440400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28/02/2022 21:42:08</td>\n",
       "      <td>1498413233698443272</td>\n",
       "      <td>$AAPL held Premarket high for a bit in morning...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>258</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>held premarket high for a bit in morning befor...</td>\n",
       "      <td>['held', 'premarket', 'high', 'bit', 'morning'...</td>\n",
       "      <td>['hold', 'premarket', 'high', 'bit', 'morning'...</td>\n",
       "      <td>0.900152</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.501733</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28/02/2022 21:30:00</td>\n",
       "      <td>1498410179972399105</td>\n",
       "      <td>$AAPL closed today at $165.12. If you bought 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>closed today at .12. if you bought 1 share of ...</td>\n",
       "      <td>['closed', 'today', 'bought', 'share', 'closin...</td>\n",
       "      <td>['close', 'today', 'buy', 'share', 'closing', ...</td>\n",
       "      <td>-0.986211</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.151741</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28/02/2022 10:28:15</td>\n",
       "      <td>1498243644431732743</td>\n",
       "      <td>$SPY #SPY #QQQ $QQQ $AMC #AMC $AAPL #AAPL $GME...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>279</td>\n",
       "      <td>1026</td>\n",
       "      <td>4</td>\n",
       "      <td>833</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>levels still valid and all levels will be rete...</td>\n",
       "      <td>['levels', 'still', 'valid', 'levels', 'retest...</td>\n",
       "      <td>['level', 'valid', 'level', 'reteste', 'up', '...</td>\n",
       "      <td>0.247874</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.187950</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28/02/2022 04:57:58</td>\n",
       "      <td>1498160526311915520</td>\n",
       "      <td>$AAPL Weekly. #AAPL formed a hammer candlestic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>18591</td>\n",
       "      <td>494</td>\n",
       "      <td>520</td>\n",
       "      <td>8381</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>weekly. formed a hammer candlestick last week,...</td>\n",
       "      <td>['weekly', 'formed', 'hammer', 'candlestick', ...</td>\n",
       "      <td>['weekly', 'form', 'hammer', 'candlestick', 'l...</td>\n",
       "      <td>-0.406989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.322088</td>\n",
       "      <td>-0.183333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date             tweet_id  \\\n",
       "0  28/02/2022 22:39:16  1498427612665987078   \n",
       "1  28/02/2022 21:42:08  1498413233698443272   \n",
       "2  28/02/2022 21:30:00  1498410179972399105   \n",
       "3  28/02/2022 10:28:15  1498243644431732743   \n",
       "4  28/02/2022 04:57:58  1498160526311915520   \n",
       "\n",
       "                                             content  replyCount  \\\n",
       "0  $SPY #SPY #QQQ $QQQ $UVXY #UVXY $AMC #AMC $AAP...           0   \n",
       "1  $AAPL held Premarket high for a bit in morning...           0   \n",
       "2  $AAPL closed today at $165.12. If you bought 1...           0   \n",
       "3  $SPY #SPY #QQQ $QQQ $AMC #AMC $AAPL #AAPL $GME...           0   \n",
       "4  $AAPL Weekly. #AAPL formed a hammer candlestic...           0   \n",
       "\n",
       "   retweetCount  likeCount  quoteCount  verified  followersCount  \\\n",
       "0             1          2           0     False             279   \n",
       "1             0          0           0     False              60   \n",
       "2             0          0           0     False              50   \n",
       "3             1          2           0     False             279   \n",
       "4             0         12           0     False           18591   \n",
       "\n",
       "   friendsCount  listedCount  mediaCount ticker  \\\n",
       "0          1026            4         833   AAPL   \n",
       "1           258            4          32   AAPL   \n",
       "2            11            0           1   AAPL   \n",
       "3          1026            4         833   AAPL   \n",
       "4           494          520        8381   AAPL   \n",
       "\n",
       "                                       content_clean  \\\n",
       "0  final liquidity pump underway. this is it. the...   \n",
       "1  held premarket high for a bit in morning befor...   \n",
       "2  closed today at .12. if you bought 1 share of ...   \n",
       "3  levels still valid and all levels will be rete...   \n",
       "4  weekly. formed a hammer candlestick last week,...   \n",
       "\n",
       "                                   content_tokenized  \\\n",
       "0  ['final', 'liquidity', 'pump', 'underway', 'su...   \n",
       "1  ['held', 'premarket', 'high', 'bit', 'morning'...   \n",
       "2  ['closed', 'today', 'bought', 'share', 'closin...   \n",
       "3  ['levels', 'still', 'valid', 'levels', 'retest...   \n",
       "4  ['weekly', 'formed', 'hammer', 'candlestick', ...   \n",
       "\n",
       "                                  content_lemmatized  Sentiment_Flair  \\\n",
       "0  ['final', 'liquidity', 'pump', 'underway', 'su...         0.997430   \n",
       "1  ['hold', 'premarket', 'high', 'bit', 'morning'...         0.900152   \n",
       "2  ['close', 'today', 'buy', 'share', 'closing', ...        -0.986211   \n",
       "3  ['level', 'valid', 'level', 'reteste', 'up', '...         0.247874   \n",
       "4  ['weekly', 'form', 'hammer', 'candlestick', 'l...        -0.406989   \n",
       "\n",
       "   Sentiment_Afinn  Sentiment_Vader  Sentiment_TextBlob  \n",
       "0             -0.6        -0.440400            0.000000  \n",
       "1              0.5         0.501733            0.380000  \n",
       "2              0.2        -0.151741            0.000000  \n",
       "3             -0.2        -0.187950            0.000000  \n",
       "4              0.0        -0.322088           -0.183333  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5052f",
   "metadata": {},
   "source": [
    "## 6. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fdc540",
   "metadata": {},
   "source": [
    "### 6.1 Merging Returns Data and Sentiment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f5259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge hourly data\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "stocks = ['AMZN', 'AAPL', 'MSFT', 'TSLA', 'ATVI', 'NVDA', 'FB', 'UBER', 'MA', 'AMD', 'INTC', 'NFLX']\n",
    "\n",
    "# Read Tweets DataFrame\n",
    "tweets2 = pd.read_parquet('allTWEETS_Processed.parquet')\n",
    "# Read News DataFrame\n",
    "news2 = pd.read_parquet('News.parquet')\n",
    "\n",
    "for i in stocks:\n",
    "\n",
    "    tweets = tweets2.loc[tweets2['ticker'] == i]\n",
    "    news = news2.loc[news2['Ticker'] == i]\n",
    "    \n",
    "    tweets.rename(columns = {'Sentiment_Flair':'T_Sentiment_Flair','Sentiment_Afinn':'T_Sentiment_Afinn',\n",
    "                             'Sentiment_Vader':'T_Sentiment_Vader','Sentiment_TextBlob':'T_Sentiment_TextBlob'}, inplace = True)\n",
    "    \n",
    "    news.rename(columns = {'Date':'date','Sentiment_Flair':'N_Sentiment_Flair','Sentiment_Afinn':'N_Sentiment_Afinn',\n",
    "                             'Sentiment_Vader':'N_Sentiment_Vader','Sentiment_TextBlob':'N_Sentiment_TextBlob'}, inplace = True)\n",
    "    \n",
    "    # Read date and sentiment scores only\n",
    "    tweets = tweets[['date', 'T_Sentiment_Flair', 'T_Sentiment_Afinn', 'T_Sentiment_Vader','T_Sentiment_TextBlob']].sort_values(by='date')\n",
    "    news = news[['date', 'N_Sentiment_Flair', 'N_Sentiment_Afinn', 'N_Sentiment_Vader','N_Sentiment_TextBlob']].sort_values(by='date')\n",
    "    \n",
    "    # Transform date to datetime\n",
    "    tweets['date'] = pd.to_datetime(tweets['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    news['date'] = pd.to_datetime(news['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    \n",
    "    # Group tweets and news by hours taking hourly average of sentiment scores each hour\n",
    "    tweets=tweets.groupby(pd.Grouper(freq='H', key='date')).mean() \n",
    "    news=news.groupby(pd.Grouper(freq='H', key='date')).mean() \n",
    "    \n",
    "    # Reset Index\n",
    "    tweets.reset_index(inplace = True)\n",
    "    news.reset_index(inplace = True)\n",
    "    \n",
    "    # Convert date to datetime again\n",
    "    tweets['date'] = pd.to_datetime(tweets['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    news['date'] = pd.to_datetime(news['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    \n",
    "    # Forward fill hours with no tweets and news data\n",
    "    tweets = tweets.ffill(axis = 0)\n",
    "    news = news.ffill(axis = 0)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "    # Read stock price\n",
    "    stock = pd.read_csv('Hourly_Price_{}.csv'.format(i))\n",
    "    \n",
    "    # Remove %z UTC timezone from stock['Datetime'] to align datetime\n",
    "    stock['Datetime'] = stock['Datetime'].astype(str)\n",
    "    stock.Datetime=stock.Datetime.str[:-6]\n",
    "    \n",
    "    # Transform date to datetime\n",
    "    stock['Datetime'] = pd.to_datetime(stock['Datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Read stock data\n",
    "    stock = stock[['Datetime', 'Open' ,'High', 'Low', 'Close', 'Adj Close','Volume']].sort_values(by='Datetime')\n",
    "    \n",
    "    # Standardize stock hour datetime \n",
    "    stock=stock.groupby(pd.Grouper(freq='H', key='Datetime')).mean() \n",
    "    \n",
    "    # Remove non-trading hours\n",
    "    stock.dropna(subset = ['Adj Close'], inplace=True)\n",
    "    \n",
    "    # Reset Index\n",
    "    stock.reset_index(inplace = True)\n",
    "    \n",
    "    # Calculate hourly stock returns\n",
    "    stock['Return'] = stock['Adj Close'].pct_change(1)\n",
    "    \n",
    "    # Rename and remove columns\n",
    "    stock.rename(columns = {'Datetime':'date'}, inplace = True)\n",
    "    stock = stock[['date','Return', 'Open' ,'High', 'Low', 'Close', 'Adj Close','Volume']]\n",
    "    \n",
    "    # Merge stock data and tweets data\n",
    "    df = pd.merge(stock, tweets, on=['date'])\n",
    "    df = pd.merge(df, news, on=['date'])\n",
    "    \n",
    "    df.to_parquet('HourlyReturn_{}.parquet'.format(i))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Merge daily data\n",
    "for i in stocks:\n",
    "\n",
    "    tweets = tweets2.loc[tweets2['ticker'] == i]\n",
    "    news = news2.loc[news2['Ticker'] == i]\n",
    "    \n",
    "    tweets.rename(columns = {'Sentiment_Flair':'T_Sentiment_Flair','Sentiment_Afinn':'T_Sentiment_Afinn',\n",
    "                             'Sentiment_Vader':'T_Sentiment_Vader','Sentiment_TextBlob':'T_Sentiment_TextBlob'}, inplace = True)\n",
    "    \n",
    "    news.rename(columns = {'Date':'date','Sentiment_Flair':'N_Sentiment_Flair','Sentiment_Afinn':'N_Sentiment_Afinn',\n",
    "                             'Sentiment_Vader':'N_Sentiment_Vader','Sentiment_TextBlob':'N_Sentiment_TextBlob'}, inplace = True)\n",
    "    \n",
    "    # Read date and sentiment scores only\n",
    "    tweets = tweets[['date', 'T_Sentiment_Flair', 'T_Sentiment_Afinn', 'T_Sentiment_Vader','T_Sentiment_TextBlob']].sort_values(by='date')\n",
    "    news = news[['date', 'N_Sentiment_Flair', 'N_Sentiment_Afinn', 'N_Sentiment_Vader','N_Sentiment_TextBlob']].sort_values(by='date')\n",
    "    \n",
    "    # Transform date to datetime\n",
    "    tweets['date'] = pd.to_datetime(tweets['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    news['date'] = pd.to_datetime(news['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    \n",
    "    # Group tweets and news by day taking daily average of sentiment scores each day\n",
    "    tweets=tweets.groupby(pd.Grouper(freq='D', key='date')).mean() \n",
    "    news=news.groupby(pd.Grouper(freq='D', key='date')).mean() \n",
    "    \n",
    "    # Reset Index\n",
    "    tweets.reset_index(inplace = True)\n",
    "    news.reset_index(inplace = True)\n",
    "    \n",
    "    # Convert date to datetime again\n",
    "    tweets['date'] = pd.to_datetime(tweets['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    news['date'] = pd.to_datetime(news['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    \n",
    "    # Forward fill hours with no tweets and news data\n",
    "    tweets = tweets.ffill(axis = 0)\n",
    "    news = news.ffill(axis = 0)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "    # Read stock price\n",
    "    stock = pd.read_csv('Price_{}.csv'.format(i))\n",
    "    \n",
    "    # Remove %z UTC timezone from stock['Datetime'] to align datetime\n",
    "    stock = stock.reset_index()\n",
    "    \n",
    "    # Transform date to datetime\n",
    "    stock['Date'] = pd.to_datetime(stock['Date'],format = \"%Y-%m-%d\")\n",
    "    \n",
    "    # Convert datetime to date\n",
    "    stock['Date'] = pd.to_datetime(stock['Date'].dt.date)\n",
    "    \n",
    "    # Read data\n",
    "    stock = stock[['Date', 'Open' ,'High', 'Low', 'Close', 'Adj Close','Volume', 'Ticker']].sort_values(by='Date')\n",
    "    \n",
    "    # Calculate daily stock returns\n",
    "    stock['Return'] = stock['Adj Close'].pct_change(1)\n",
    "    \n",
    "    # Rename and remove columns\n",
    "    stock.rename(columns = {'Date':'date'}, inplace = True)\n",
    "    stock = stock[['date','Return', 'Open' ,'High', 'Low', 'Close', 'Adj Close','Volume', 'Ticker']]\n",
    "    \n",
    "    # Merge stock data and tweets data\n",
    "    df = pd.merge(stock, tweets, on=['date'])\n",
    "    df = pd.merge(df, news, on=['date'])\n",
    "    \n",
    "    df.to_parquet('DailyReturn_{}.parquet'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e70dd5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Return</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>T_Sentiment_Flair</th>\n",
       "      <th>T_Sentiment_Afinn</th>\n",
       "      <th>T_Sentiment_Vader</th>\n",
       "      <th>T_Sentiment_TextBlob</th>\n",
       "      <th>N_Sentiment_Flair</th>\n",
       "      <th>N_Sentiment_Afinn</th>\n",
       "      <th>N_Sentiment_Vader</th>\n",
       "      <th>N_Sentiment_TextBlob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>152.830002</td>\n",
       "      <td>154.979996</td>\n",
       "      <td>152.339996</td>\n",
       "      <td>152.509995</td>\n",
       "      <td>152.093964</td>\n",
       "      <td>80313700</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.439025</td>\n",
       "      <td>0.075238</td>\n",
       "      <td>0.129183</td>\n",
       "      <td>0.261108</td>\n",
       "      <td>-0.451613</td>\n",
       "      <td>0.101139</td>\n",
       "      <td>0.166658</td>\n",
       "      <td>0.323046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>153.869995</td>\n",
       "      <td>154.720001</td>\n",
       "      <td>152.399994</td>\n",
       "      <td>153.649994</td>\n",
       "      <td>153.230850</td>\n",
       "      <td>71115500</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.389312</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.239850</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>-0.375664</td>\n",
       "      <td>0.022325</td>\n",
       "      <td>0.152422</td>\n",
       "      <td>0.300089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>153.759995</td>\n",
       "      <td>154.630005</td>\n",
       "      <td>153.089996</td>\n",
       "      <td>154.300003</td>\n",
       "      <td>153.879089</td>\n",
       "      <td>57808700</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.321581</td>\n",
       "      <td>0.124074</td>\n",
       "      <td>0.056036</td>\n",
       "      <td>0.042972</td>\n",
       "      <td>-0.465355</td>\n",
       "      <td>-0.021327</td>\n",
       "      <td>0.042717</td>\n",
       "      <td>-0.135096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-07</td>\n",
       "      <td>0.015489</td>\n",
       "      <td>154.970001</td>\n",
       "      <td>157.259995</td>\n",
       "      <td>154.389999</td>\n",
       "      <td>156.690002</td>\n",
       "      <td>156.262573</td>\n",
       "      <td>82278300</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.575571</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.107470</td>\n",
       "      <td>-0.007832</td>\n",
       "      <td>-0.310510</td>\n",
       "      <td>0.341669</td>\n",
       "      <td>0.350883</td>\n",
       "      <td>0.272359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-08</td>\n",
       "      <td>-0.010084</td>\n",
       "      <td>156.979996</td>\n",
       "      <td>157.039993</td>\n",
       "      <td>153.979996</td>\n",
       "      <td>155.110001</td>\n",
       "      <td>154.686874</td>\n",
       "      <td>74420200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.504929</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>-0.115833</td>\n",
       "      <td>-0.263752</td>\n",
       "      <td>0.302215</td>\n",
       "      <td>0.449849</td>\n",
       "      <td>0.297079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    Return        Open        High         Low       Close  \\\n",
       "0 2021-09-01  0.004479  152.830002  154.979996  152.339996  152.509995   \n",
       "1 2021-09-02  0.007475  153.869995  154.720001  152.399994  153.649994   \n",
       "2 2021-09-03  0.004230  153.759995  154.630005  153.089996  154.300003   \n",
       "3 2021-09-07  0.015489  154.970001  157.259995  154.389999  156.690002   \n",
       "4 2021-09-08 -0.010084  156.979996  157.039993  153.979996  155.110001   \n",
       "\n",
       "    Adj Close    Volume Ticker  T_Sentiment_Flair  T_Sentiment_Afinn  \\\n",
       "0  152.093964  80313700   AAPL           0.439025           0.075238   \n",
       "1  153.230850  71115500   AAPL           0.389312           0.150000   \n",
       "2  153.879089  57808700   AAPL           0.321581           0.124074   \n",
       "3  156.262573  82278300   AAPL           0.575571           0.002564   \n",
       "4  154.686874  74420200   AAPL           0.504929           0.011111   \n",
       "\n",
       "   T_Sentiment_Vader  T_Sentiment_TextBlob  N_Sentiment_Flair  \\\n",
       "0           0.129183              0.261108          -0.451613   \n",
       "1           0.239850              0.012037          -0.375664   \n",
       "2           0.056036              0.042972          -0.465355   \n",
       "3           0.107470             -0.007832          -0.310510   \n",
       "4           0.053732             -0.115833          -0.263752   \n",
       "\n",
       "   N_Sentiment_Afinn  N_Sentiment_Vader  N_Sentiment_TextBlob  \n",
       "0           0.101139           0.166658              0.323046  \n",
       "1           0.022325           0.152422              0.300089  \n",
       "2          -0.021327           0.042717             -0.135096  \n",
       "3           0.341669           0.350883              0.272359  \n",
       "4           0.302215           0.449849              0.297079  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display dataframe for AAPL as sample\n",
    "aapl = pd.read_parquet('DailyReturn_AAPL.parquet')\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60767ce0",
   "metadata": {},
   "source": [
    "### 6.2 Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63613a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set regression parameters\n",
    "data1 = ['T', 'N']\n",
    "time1 = ['Daily', 'Hourly']\n",
    "mod1 = ['Flair', 'TextBlob', 'Vader', 'Afinn']\n",
    "\n",
    "\n",
    "# Set up Regression\n",
    "def reg (data, time, mod):\n",
    "\n",
    "    # Select stocks \n",
    "    stocks1 = ['AMZN', 'AAPL', 'MSFT', 'TSLA', 'NVDA', 'FB', 'UBER', 'NFLX']\n",
    "    \n",
    "    for i in stocks1:\n",
    "        test = pd.read_parquet('{}Return_{}.parquet'.format(time,i))\n",
    "        \n",
    "     \n",
    "        test = test[['Return', '{}_Sentiment_{}'.format(data, mod)]]\n",
    "\n",
    "        # Get the lagged sentiment scores\n",
    "        test['{}_Sentiment_{}_Lag1'.format(data, mod)] = test['{}_Sentiment_{}'.format(data, mod)].shift(1)\n",
    "        test['{}_Sentiment_{}_Lag2'.format(data, mod)] = test['{}_Sentiment_{}'.format(data, mod)].shift(2)\n",
    "        test['{}_Sentiment_{}_Lag3'.format(data, mod)] = test['{}_Sentiment_{}'.format(data, mod)].shift(3)\n",
    "        test['{}_Sentiment_{}_Lag6'.format(data, mod)] = test['{}_Sentiment_{}'.format(data, mod)].shift(6)\n",
    "\n",
    "        # Select the columns as independent variables for regression\n",
    "        all_columns = \"+\".join(np.delete(test.columns, [0]))\n",
    "        my_formula = \"Return~\" + all_columns\n",
    "        \n",
    "        # Get the coefficients and p-values\n",
    "        coef = smf.ols(formula = my_formula, data = test).fit().params\n",
    "        pval = smf.ols(formula = my_formula, data = test).fit().pvalues\n",
    "        table = pd.concat({'Coef': coef,'P-value': pval}, axis=1)\n",
    "\n",
    "        # Create a table to present the results\n",
    "        table['Significance'] = np.where(table['P-value'] <= 0.05, 'Yes', 'No')\n",
    "        table['Correlation'] = np.where((table['Coef'] >0 ) & (table['Significance'] =='Yes' ), 'Postive', 'Negative/No')\n",
    "\n",
    "        # Output the table\n",
    "        print (i)\n",
    "        print (table)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression results for news\n",
    "for i in mod1:  \n",
    "     reg('N', 'Hourly', i)\n",
    "for i in mod1:  \n",
    "     reg('N', 'Daily', i)\n",
    "     \n",
    "\n",
    "# Regression results for tweets\n",
    "for i in mod1:  \n",
    "     reg('T', 'Hourly', i)\n",
    "for i in mod1:  \n",
    "     reg('T', 'Daily', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1073ec64",
   "metadata": {},
   "source": [
    "## 7. Trading Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170a9cc",
   "metadata": {},
   "source": [
    "### 7.1 Strategy 1: 0.2 buy-sell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690d740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DataFrame (sample: AMZN)\n",
    "df = pd.read_parquet('DailyReturn_AMZN.parquet')\n",
    "\n",
    "# Convert columns to list\n",
    "df_close = df['Close'].tolist()\n",
    "df_adj_close = df['Adj Close'].tolist()\n",
    "df_ticker = df['Ticker'].tolist()\n",
    "T_Sentiment_Flair = df['T_Sentiment_Flair'].tolist()\n",
    "T_Sentiment_Afinn = df['T_Sentiment_Afinn'].tolist()\n",
    "T_Sentiment_Vader = df['T_Sentiment_Vader'].tolist()\n",
    "T_Sentiment_TextBlob = df['T_Sentiment_TextBlob'].tolist()\n",
    "\n",
    "\n",
    "def change_buy_sell():\n",
    "    # Set ac_balance (Account Balance) as $1M\n",
    "    ac_balance = 1000000\n",
    "    # Set amount as number of stocks\n",
    "    amount=0\n",
    "    # Initialize buy price\n",
    "    buyprice = 0\n",
    "    # Initialize sell price \n",
    "    sellprice = 0\n",
    "    # Initialize Ireturn(investment return) which is the price difference of each trade \n",
    "    Ireturn = 0\n",
    "    i=0\n",
    "    securitiesMV = 0 \n",
    "    # Initalize a list of return \n",
    "    Return = []\n",
    "    for i in range(len(sscore)-1):\n",
    "            # Buy_action\n",
    "            # If sentiment score increases by 0.2 over a day\n",
    "             if(sscore[i+1]-sscore[i])>=0.2:\n",
    "            # Set the buy price of this trade \n",
    "                 buyprice = stock_price[i+1]\n",
    "            # Calculte the amount of stock and Market Value of securities bought\n",
    "            # The two lines below are the same but makes this code more readable\n",
    "                 amount = ac_balance/buyprice\n",
    "                 securitiesMV = amount * buyprice\n",
    "            # Sell_action \n",
    "            # If sentiment score decreases by 0.2 over a day\n",
    "             elif(sscore[i+1]-sscore[i]) <=-0.2: \n",
    "                 # Set the sell price of this trade \n",
    "                 sellprice = stock_price[i+1]\n",
    "                 # Calculte the Market Value of securities sold\n",
    "                 sellingMV = (amount*sellprice)\n",
    "                 # Avoid calculating the price difference when there is no trade \n",
    "                 if buyprice != 0:\n",
    "                     # Calcualte price difference \n",
    "                     Ireturn = sellingMV- securitiesMV  \n",
    "                     # Add to list\n",
    "                     Return.append(Ireturn)\n",
    "                     # Reset null trade position and be ready to execute next trade\n",
    "                     buyprice = sellprice = amount = 0\n",
    "                     # Update Account Balance\n",
    "                     ac_balance = Ireturn + ac_balance\n",
    "    # Calculate the ROI\n",
    "    return  (sum(Return)/1000000)*100\n",
    "\n",
    "# Find out the best among sentiment anaylsis models and the avg. return in %\n",
    "winner= None\n",
    "winning_score=-1000000000000\n",
    "change_buy_sell_avg=0\n",
    "\n",
    "sscore= T_Sentiment_Flair\n",
    "stock_price= df_close\n",
    "print('<<Flair>>   G/L',change_buy_sell(),'%')\n",
    "change_buy_sell_avg+=change_buy_sell()\n",
    "if change_buy_sell() >= winning_score:\n",
    "    winner = 'Flair'\n",
    "    winning_score=change_buy_sell()\n",
    "\n",
    "sscore= T_Sentiment_Afinn\n",
    "stock_price= df_close\n",
    "print('<<Afinn>>    G/L',change_buy_sell(),'%')\n",
    "change_buy_sell_avg+=change_buy_sell()\n",
    "if change_buy_sell() >= winning_score:\n",
    "    winner = 'Flair'\n",
    "    winning_score=change_buy_sell()\n",
    "    \n",
    "sscore= T_Sentiment_Vader\n",
    "stock_price= df_close\n",
    "print('<<Vader>>    G/L',change_buy_sell(),'%')\n",
    "change_buy_sell_avg+=change_buy_sell()\n",
    "if change_buy_sell() >= winning_score:\n",
    "    winner = 'Flair'\n",
    "    winning_score=change_buy_sell()\n",
    "    \n",
    "sscore= T_Sentiment_TextBlob\n",
    "stock_price= df_close\n",
    "print('<<TextBlob>>    G/L',change_buy_sell(),'%')\n",
    "change_buy_sell_avg+=change_buy_sell()\n",
    "if change_buy_sell() >= winning_score:\n",
    "    winner = 'Flair'\n",
    "    winning_score=change_buy_sell()\n",
    "    \n",
    "print('   [[',winner,winning_score,'%',']]')\n",
    "print('                                          Strategy[0.2 BS] avg',change_buy_sell_avg/4,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642444cb",
   "metadata": {},
   "source": [
    "### 7.2 Strategy 2: Cross Trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c83d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_trade():\n",
    "    # Set initial trading amount of stock as 0 \n",
    "    amount=0\n",
    "    # Set beginning account balance as 1000000\n",
    "    Ac_balance=1000000\n",
    "    # Set buy price, sell price and return as 0\n",
    "    buyprice = 0\n",
    "    sellprice = 0\n",
    "    Ireturn = 0\n",
    "    i=0\n",
    "    securitiesMV = 0 \n",
    "    # Create a list for each return \n",
    "    Return = []\n",
    "    for i in range(21,len(sscore)-1):\n",
    "        # Calculate 2day and 4day moving average \n",
    "        # Declare variables (fl = fast line; sl = slow line)\n",
    "        fl=sum(sscore[i-2:i])/2\n",
    "        sl=sum(sscore[i-4:i])/4\n",
    "        # Calculate 2day and 4day moving average on a day before \n",
    "        # In order to spot if there is a breakthough (cross)\n",
    "        # Declare variables (cfl = fast line for comparsion; sl = slow line for comparsion)\n",
    "        cfl=sum(sscore[i-3:i-1])/2\n",
    "        csl=sum(sscore[i-5:i-1])/4\n",
    "        \n",
    "        \n",
    "        # Trigger buy action if fast line is above slow line and if there is a twist\n",
    "        # Twist = (slow line - buy price) changing from negative to positive \n",
    "        if sl-fl <=0 and (cfl-csl)*(fl-sl)<=0: \n",
    "            # Buy action\n",
    "            # Set buy price \n",
    "            buyprice = stock_price[i+1]\n",
    "            # Calculate amount of stock and securities market value \n",
    "            amount = Ac_balance/buyprice\n",
    "            securitiesMV = amount * buyprice\n",
    "        # Sell_action \n",
    "        # Trigger sell action if fast line is below slow line and if there is a twist\n",
    "        # Twist = (slow line - buy price) changing from positive to negative \n",
    "        elif sl-fl >=0 and (cfl-csl)*(fl-sl)<=0:   \n",
    "           # Set sellprice and selling market value \n",
    "           sellprice = stock_price[i+1]\n",
    "           sellingMV = (amount*sellprice)\n",
    "           # Avoid selling before buying \n",
    "           if buyprice != 0:\n",
    "               # Calculate return (price difference)\n",
    "               Ireturn = sellingMV-securitiesMV\n",
    "               # Add return to the list \n",
    "               Return.append(Ireturn)\n",
    "               # Reset null trade position and be ready to execute next trade\n",
    "               buyprice = sellprice = amount = 0\n",
    "               # Update account balance \n",
    "               Ac_balance = Ireturn + Ac_balance\n",
    "    # Calculate Return ROI (%)           \n",
    "    return  ((sum(Return))/1000000)*100\n",
    "\n",
    "# Find out the best among sentiment anaylsis models and the avg. return in %\n",
    "\n",
    "winner= None\n",
    "winning_score=-1000000000000000\n",
    "cross_avg=0\n",
    "\n",
    "sscore= T_Sentiment_Flair\n",
    "stock_price= df_close\n",
    "print('<<Flair>>   G/L:',cross_trade(),'%')\n",
    "cross_avg+=cross_trade()\n",
    "if cross_trade() >= winning_score:\n",
    "    winner = 'Flair'\n",
    "    winning_score=cross_trade()\n",
    "\n",
    "sscore= T_Sentiment_Afinn\n",
    "stock_price= df_close\n",
    "print('<<Afinn>>   G/L:',cross_trade(),'%')\n",
    "cross_avg+=cross_trade()\n",
    "if cross_trade() >= winning_score:\n",
    "    winner = 'Afinn'\n",
    "    winning_score=cross_trade()\n",
    "\n",
    "sscore= T_Sentiment_Vader\n",
    "stock_price= df_close\n",
    "print('<<Vader>>   G/L:',cross_trade(),'%')\n",
    "cross_avg+=cross_trade()\n",
    "if cross_trade() >= winning_score:\n",
    "    winner = 'Vader'\n",
    "    winning_score=cross_trade()\n",
    "\n",
    "sscore= T_Sentiment_TextBlob\n",
    "stock_price= df_close\n",
    "print('<<TextBlob>>   G/L:',cross_trade(),'%')\n",
    "cross_avg+=cross_trade()\n",
    "if cross_trade() >= winning_score:\n",
    "    winner = 'TextBlob'\n",
    "    winning_score=cross_trade()\n",
    "\n",
    "# Calculate the Avg. return of all eight outcomes\n",
    "print('   [[',winner,winning_score,'%',']]')\n",
    "print('                                          Strategy[cross] avg',cross_avg/4,'%')     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2ca9d",
   "metadata": {},
   "source": [
    "### 7.3 Overall Average ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Master_AVG:',((change_buy_sell_avg/4)+(cross_avg/4))/2,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
