{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0565e31e",
   "metadata": {},
   "source": [
    "# <h1 style='font-size:2.2rem;color:orange;'>Stock Markets Sensitivity to Social vs. News Media Sentiment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e391cfd4",
   "metadata": {},
   "source": [
    "## 1. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5fba3e",
   "metadata": {},
   "source": [
    "## 2. Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bs4 as bs\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import time\n",
    "import concurrent.futures\n",
    "import re\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import yfinance as yf\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import string\n",
    "import itertools\n",
    "from segtok.segmenter import split_single\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import fastparquet\n",
    "\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "from segtok.segmenter import split_single\n",
    "from afinn import Afinn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import statsmodels.api as sm # statistical models including regression\n",
    "import scipy as sp # scientific calculation toolkit\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424bfe38",
   "metadata": {},
   "source": [
    "## 3. Download datasets | Stock Data | News Data | Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf58f7bd",
   "metadata": {},
   "source": [
    "### 3.1 Scrap Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "tickers= ['AAPL', 'MSFT', 'TSLA', 'AMZN', 'ATVI', 'NVDA', 'FB', 'UBER', 'V', 'MA', 'AVGO', 'CSCO', 'ADBE', 'CRM', 'AMD', 'INTC', 'NFLX']\n",
    "\n",
    "for ticker in tickers:\n",
    "#Get the data for the stock each stock\n",
    "    data = yf.download(ticker,'2021-09-01','2022-03-01')\n",
    "    data['Ticker'] = ticker\n",
    "    data.to_csv('Price_'+ str(ticker) + '.csv')\n",
    "\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "#Get the data for the stock each stock\n",
    "    data = yf.download(ticker,'2021-09-01','2022-03-01',interval=\"60m\")\n",
    "    data['Ticker'] = ticker\n",
    "    data.to_csv('Hourly_Price_'+ str(ticker) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f5813e",
   "metadata": {},
   "source": [
    "### 3.2 Scrap News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion to scrape news content, from the news links\n",
    "def linkScraper(newsLinks):\n",
    "    try:\n",
    "        linkResp = requests.get(newsLinks)\n",
    "        linkSoup = bs.BeautifulSoup(linkResp.text, 'lxml')\n",
    "        \n",
    "    except:\n",
    "        print(newsLinks) \n",
    "    try:\n",
    "        url.append(linkSoup.find('meta',{\"property\":\"og:url\"}).get('content'))\n",
    "    except:\n",
    "        url.append(np.nan)\n",
    "    try:\n",
    "        title.append(linkSoup.find('h1',{\"class\":\"text__text__1FZLe text__dark-grey__3Ml43 text__medium__1kbOh text__heading_2__1K_hh heading__base__2T28j heading__heading_2__3Fcw5\"}).text)\n",
    "    except:\n",
    "        title.append(np.nan)\n",
    "    try:        \n",
    "        date.append(linkSoup.find('span',{\"class\":\"date-line__date__23Ge-\"}).text + ' ' + linkSoup.findAll('span',{\"class\":\"date-line__date__23Ge-\"})[1].text)\n",
    "    except:\n",
    "        date.append(np.nan)\n",
    "    try:\n",
    "        author.append(linkSoup.find('a',{\"class\":\"author-name__author__1gx5k\"}).text)\n",
    "    except:\n",
    "        author.append(np.nan)\n",
    "    try:\n",
    "        content.append(linkSoup.find('div',{\"class\":\"article-body__content__3VtU3 paywall-article\"}).get_text(separator=' '))\n",
    "    except:\n",
    "        content.append(np.nan)\n",
    "    \n",
    "\n",
    "#Function to scrape all news links\n",
    "def newScraper():\n",
    "    symbols = ['Amazon', 'Apple', 'Microsoft', 'Tesla', 'Blizzard', 'Nvidia', 'Facebook',\n",
    "               'Uber', 'Mastercard', 'AMD', 'Intel', 'Netflix']\n",
    "    \n",
    "    global news, stock, url, title, date, author, content\n",
    "    stock = []\n",
    "    url = []\n",
    "    title = []   \n",
    "    date = []\n",
    "    author = []  \n",
    "    content = [] \n",
    "    \n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "    \n",
    "    for symbol in symbols: \n",
    "        searchFormat = 'https://www.reuters.com/site-search/?query={}&offset={}&sort=newest&date=past_year'  \n",
    "        newsLinks = []\n",
    "\n",
    "        for i in range(1,180):\n",
    "            try: \n",
    "                driver.get(searchFormat.format(symbol, i*10-10))\n",
    "                driver.implicitly_wait(3)\n",
    "                time.sleep(1) \n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for attempt in range(3):\n",
    "                try: \n",
    "                    elems = driver.find_elements_by_css_selector(\".search-results__item__2oqiX [href]\")\n",
    "                    if elems != []:\n",
    "                        for elem in elems:\n",
    "                            newsLinks.append(elem.get_attribute('href'))\n",
    "\n",
    "                    else:\n",
    "                        print('no elements, go to next stock')\n",
    "                        break \n",
    "                    \n",
    "                except: \n",
    "                    print ('webpage error, retrying again')\n",
    "                    continue\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            break\n",
    "    \n",
    " \n",
    "\n",
    "        newsLinks = list(set(newsLinks))\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor: \n",
    "            executor.map(linkScraper, newsLinks)\n",
    "        stock.extend([symbol] * len(newsLinks))\n",
    "        \n",
    "        print(str(symbol) + \" stock length is : \" + str(len(stock)))\n",
    "        print(str(symbol) + \" url length is : \" + str(len(url)))\n",
    "        print(str(symbol) + \" title length is : \" + str(len(title)))\n",
    "        print(str(symbol) + \" date length is : \" + str(len(date)))\n",
    "        print(str(symbol) + \" author length is : \" + str(len(author)))\n",
    "        print(str(symbol) + \" content length is : \" + str(len(content)))\n",
    "    \n",
    "    news = pd.DataFrame({'Stock': stock, 'Date':date, 'Title': title, 'Author': author, 'Content':content, 'Url':url})  \n",
    "    \n",
    "    return (news)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b77d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Clean</th>\n",
       "      <th>Content_Clean_Token</th>\n",
       "      <th>Url</th>\n",
       "      <th>Sentiment_Flair</th>\n",
       "      <th>Sentiment_Afinn</th>\n",
       "      <th>Sentiment_Vader</th>\n",
       "      <th>Sentiment_TextBlob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>02/07/2021 21:31:00</td>\n",
       "      <td>AMD directors dodge shareholder derivative sui...</td>\n",
       "      <td>Jody Godoy</td>\n",
       "      <td>Summary Related documents Shareholder showed n...</td>\n",
       "      <td>related document shareholder show basis skip d...</td>\n",
       "      <td>['related' 'document' 'shareholder' 'show' 'ba...</td>\n",
       "      <td>https://www.reuters.com/legal/litigation/amd-d...</td>\n",
       "      <td>-0.600430</td>\n",
       "      <td>-0.780220</td>\n",
       "      <td>-0.593653</td>\n",
       "      <td>-0.656827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>27/04/2021 20:27:00</td>\n",
       "      <td>AMD lifts revenue forecast, CEO says supply ch...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>April 27 (Reuters) - Advanced Micro Devices In...</td>\n",
       "      <td>advance micro devices inc amd raise annual rev...</td>\n",
       "      <td>['advance' 'micro' 'devices' 'inc' 'amd' 'rais...</td>\n",
       "      <td>https://www.reuters.com/technology/amd-lifts-a...</td>\n",
       "      <td>0.370084</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.780044</td>\n",
       "      <td>0.589689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>25/05/2021 13:00:00</td>\n",
       "      <td>Oracle launches Arm-based cloud computing serv...</td>\n",
       "      <td>Stephen Nellis</td>\n",
       "      <td>May 25 (Reuters) - Oracle Corp  (ORCL.N)  on T...</td>\n",
       "      <td>oracle corp orcl tuesday launch cloud computin...</td>\n",
       "      <td>['oracle' 'corp' 'orcl' 'tuesday' 'launch' 'cl...</td>\n",
       "      <td>https://www.reuters.com/technology/oracle-laun...</td>\n",
       "      <td>0.436454</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>-0.524692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>29/11/2021 20:18:00</td>\n",
       "      <td>Wall Street regains some ground after virus pu...</td>\n",
       "      <td>Ambar Warrick</td>\n",
       "      <td>Summary Companies (Updates prices, adds commen...</td>\n",
       "      <td>company update price add commentary change byl...</td>\n",
       "      <td>['company' 'update' 'price' 'add' 'commentary'...</td>\n",
       "      <td>https://www.reuters.com/markets/europe/wall-st...</td>\n",
       "      <td>-0.482530</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.200357</td>\n",
       "      <td>0.235957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>21/09/2021 06:02:00</td>\n",
       "      <td>Novartis buys gene therapy firm Arctos Medical...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>ZURICH, Sept 21 (Reuters) - Swiss drugmaker No...</td>\n",
       "      <td>zurich sept swiss drugmaker novartis novn say ...</td>\n",
       "      <td>['zurich' 'sept' 'swiss' 'drugmaker' 'novartis...</td>\n",
       "      <td>https://www.reuters.com/business/healthcare-ph...</td>\n",
       "      <td>0.250985</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.408526</td>\n",
       "      <td>-0.215686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Ticker Stock                 Date  \\\n",
       "0           0    AMD   AMD  02/07/2021 21:31:00   \n",
       "1           1    AMD   AMD  27/04/2021 20:27:00   \n",
       "2           2    AMD   AMD  25/05/2021 13:00:00   \n",
       "3           3    AMD   AMD  29/11/2021 20:18:00   \n",
       "4           4    AMD   AMD  21/09/2021 06:02:00   \n",
       "\n",
       "                                               Title          Author  \\\n",
       "0  AMD directors dodge shareholder derivative sui...      Jody Godoy   \n",
       "1  AMD lifts revenue forecast, CEO says supply ch...         Reuters   \n",
       "2  Oracle launches Arm-based cloud computing serv...  Stephen Nellis   \n",
       "3  Wall Street regains some ground after virus pu...   Ambar Warrick   \n",
       "4  Novartis buys gene therapy firm Arctos Medical...         Reuters   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Summary Related documents Shareholder showed n...   \n",
       "1  April 27 (Reuters) - Advanced Micro Devices In...   \n",
       "2  May 25 (Reuters) - Oracle Corp  (ORCL.N)  on T...   \n",
       "3  Summary Companies (Updates prices, adds commen...   \n",
       "4  ZURICH, Sept 21 (Reuters) - Swiss drugmaker No...   \n",
       "\n",
       "                                       Content_Clean  \\\n",
       "0  related document shareholder show basis skip d...   \n",
       "1  advance micro devices inc amd raise annual rev...   \n",
       "2  oracle corp orcl tuesday launch cloud computin...   \n",
       "3  company update price add commentary change byl...   \n",
       "4  zurich sept swiss drugmaker novartis novn say ...   \n",
       "\n",
       "                                 Content_Clean_Token  \\\n",
       "0  ['related' 'document' 'shareholder' 'show' 'ba...   \n",
       "1  ['advance' 'micro' 'devices' 'inc' 'amd' 'rais...   \n",
       "2  ['oracle' 'corp' 'orcl' 'tuesday' 'launch' 'cl...   \n",
       "3  ['company' 'update' 'price' 'add' 'commentary'...   \n",
       "4  ['zurich' 'sept' 'swiss' 'drugmaker' 'novartis...   \n",
       "\n",
       "                                                 Url  Sentiment_Flair  \\\n",
       "0  https://www.reuters.com/legal/litigation/amd-d...        -0.600430   \n",
       "1  https://www.reuters.com/technology/amd-lifts-a...         0.370084   \n",
       "2  https://www.reuters.com/technology/oracle-laun...         0.436454   \n",
       "3  https://www.reuters.com/markets/europe/wall-st...        -0.482530   \n",
       "4  https://www.reuters.com/business/healthcare-ph...         0.250985   \n",
       "\n",
       "   Sentiment_Afinn  Sentiment_Vader  Sentiment_TextBlob  \n",
       "0        -0.780220        -0.593653           -0.656827  \n",
       "1         0.705882         0.780044            0.589689  \n",
       "2         0.882353         0.281721           -0.524692  \n",
       "3         0.025641         0.200357            0.235957  \n",
       "4         0.047619         0.408526           -0.215686  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6edeab6",
   "metadata": {},
   "source": [
    "### 3.3 Scrap Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['AMZN', 'AAPL', 'MSFT', 'TSLA', 'ATVI', 'NVDA', 'FB', 'UBER', 'MA', 'AMD', 'INTC', 'NFLX']\n",
    "for i in tickers:\n",
    "# Using OS library to call CLI commands in Python\n",
    "    search_term = '#{ticker} ${ticker}'.format(ticker = i)\n",
    "    snscrape_code = \"snscrape --jsonl --since 2021-09-01 twitter-search \\\"{x} until:2022-03-01\\\" > {ticker}_tweets.json\".format(x = search_term, ticker = i)\n",
    "    os.system(snscrape_code)\n",
    "\n",
    "# Reads the json generated from the CLI commands above and creates a pandas dataframe\n",
    "    read_path = '{ticker}_tweets.json'.format(ticker = i)\n",
    "    raw_tweets = pd.read_json(read_path, lines=True)\n",
    "\n",
    "# Filter English tweets\n",
    "    raw_tweets = raw_tweets[raw_tweets.lang == 'en']\n",
    "    raw_tweets = raw_tweets.rename(columns={'id': 'tweet_id'})\n",
    "    \n",
    "# Filter useful columns\n",
    "    raw_tweets = raw_tweets[['date','tweet_id','content','user','replyCount','retweetCount','likeCount','quoteCount','hashtags']]\n",
    "    \n",
    "# Fetch user column dictionary data\n",
    "    df = pd.concat([raw_tweets.drop(['user'], axis=1), raw_tweets['user'].apply(pd.Series)], axis=1)\n",
    "    df = df[['date','tweet_id','content','replyCount','retweetCount','likeCount','quoteCount', 'verified','followersCount', 'friendsCount', 'listedCount', 'mediaCount']]\n",
    "    df['ticker'] = i\n",
    "\n",
    "# Remove duplicated tweets to avoid bot tweets\n",
    "    df = df.drop_duplicates(subset=['content'], keep='first')\n",
    "\n",
    "#Run pre-processing function\n",
    "    df['content'] = df['content'].apply(PreprocessTweet)\n",
    "    \n",
    "# Output to csv\n",
    "    df.to_csv(os.path.join('tweet_{ticker}.csv'.format(ticker = i)), index=False)\n",
    "    print('~~ Finished outputting: ' + 'tweet_{ticker}.csv'.format(ticker = i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c819a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>content</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>verified</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>listedCount</th>\n",
       "      <th>mediaCount</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-28 07:00:22+00:00</th>\n",
       "      <td>1498191328072675331</td>\n",
       "      <td>$NFLX Weekly. #NFLX 2 hammer candlesticks (one...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>18590</td>\n",
       "      <td>494</td>\n",
       "      <td>520</td>\n",
       "      <td>8381</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-24 12:10:07+00:00</th>\n",
       "      <td>1496819727708135428</td>\n",
       "      <td>$NFLX whoops #NFLX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>786</td>\n",
       "      <td>58</td>\n",
       "      <td>25</td>\n",
       "      <td>3007</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-23 15:15:28+00:00</th>\n",
       "      <td>1496503985951641605</td>\n",
       "      <td>$nflx #nflx + 48% gain already this AM #tradin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-23 00:01:18+00:00</th>\n",
       "      <td>1496273928502841344</td>\n",
       "      <td>#Netflix $NFLX #NFLX What a horrendous looking...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>524</td>\n",
       "      <td>1054</td>\n",
       "      <td>6</td>\n",
       "      <td>1328</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-22 19:25:44+00:00</th>\n",
       "      <td>1496204581268721664</td>\n",
       "      <td>$NFLX - #NFLX chart on</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1842</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>10933</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      tweet_id  \\\n",
       "date                                             \n",
       "2022-02-28 07:00:22+00:00  1498191328072675331   \n",
       "2022-02-24 12:10:07+00:00  1496819727708135428   \n",
       "2022-02-23 15:15:28+00:00  1496503985951641605   \n",
       "2022-02-23 00:01:18+00:00  1496273928502841344   \n",
       "2022-02-22 19:25:44+00:00  1496204581268721664   \n",
       "\n",
       "                                                                     content  \\\n",
       "date                                                                           \n",
       "2022-02-28 07:00:22+00:00  $NFLX Weekly. #NFLX 2 hammer candlesticks (one...   \n",
       "2022-02-24 12:10:07+00:00                                $NFLX whoops #NFLX    \n",
       "2022-02-23 15:15:28+00:00  $nflx #nflx + 48% gain already this AM #tradin...   \n",
       "2022-02-23 00:01:18+00:00  #Netflix $NFLX #NFLX What a horrendous looking...   \n",
       "2022-02-22 19:25:44+00:00                            $NFLX - #NFLX chart on    \n",
       "\n",
       "                           replyCount  retweetCount  likeCount  quoteCount  \\\n",
       "date                                                                         \n",
       "2022-02-28 07:00:22+00:00           0             0          4           0   \n",
       "2022-02-24 12:10:07+00:00           0             0          0           0   \n",
       "2022-02-23 15:15:28+00:00           0             0          1           0   \n",
       "2022-02-23 00:01:18+00:00           0             0          0           0   \n",
       "2022-02-22 19:25:44+00:00           0             0          0           0   \n",
       "\n",
       "                           verified  followersCount  friendsCount  \\\n",
       "date                                                                \n",
       "2022-02-28 07:00:22+00:00     False           18590           494   \n",
       "2022-02-24 12:10:07+00:00     False             786            58   \n",
       "2022-02-23 15:15:28+00:00     False              20            37   \n",
       "2022-02-23 00:01:18+00:00     False             524          1054   \n",
       "2022-02-22 19:25:44+00:00     False            1842             0   \n",
       "\n",
       "                           listedCount  mediaCount ticker  \n",
       "date                                                       \n",
       "2022-02-28 07:00:22+00:00          520        8381   NFLX  \n",
       "2022-02-24 12:10:07+00:00           25        3007   NFLX  \n",
       "2022-02-23 15:15:28+00:00            0          39   NFLX  \n",
       "2022-02-23 00:01:18+00:00            6        1328   NFLX  \n",
       "2022-02-22 19:25:44+00:00           34       10933   NFLX  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d098a5f0",
   "metadata": {},
   "source": [
    "## 4. Data Pre-processing | Stock Data | News Data | Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9987393e",
   "metadata": {},
   "source": [
    "### 4.1 News Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04390fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop nan\n",
    "news = news.dropna()\n",
    "news['Content_Clean'] = news.Content\n",
    "news['Content_Clean'] = [i.replace('Register now for FREE unlimited access to Reuters.com Register ', '')\n",
    "            .replace(' Our Standards:  The Thomson Reuters Trust Principles.', '') for i in news.Content_Clean]\n",
    "\n",
    "#Lower case\n",
    "news.Content_Clean = news.Content_Clean.map(lambda x: x.lower())\n",
    "\n",
    "#Remove symbols\n",
    "news.Content_Clean = news.Content_Clean.map(lambda x: re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ', x))\n",
    "news.Content_Clean = news.Content_Clean.map(lambda x: re.sub('@[^\\s]+',' ', x))\n",
    "news.Content_Clean = news.Content_Clean.map(lambda x: re.sub('[,.\\'\"!+?\\-=)(*><&/;:$%]', ' ', x))\n",
    "news.Content_Clean = news.Content_Clean.map(lambda x: re.sub('[\\s]+', ' ', x))\n",
    "\n",
    "\n",
    "\n",
    "#Insert ticker column for stocks\n",
    "ticker = ['AMZN', 'AAPL', 'MSFT', 'TSLA', 'ATVI', 'NVDA', 'FB', 'UBER', 'MA', 'AMD', 'INTC', 'NFLX']\n",
    "stockDict = dict(zip(news.Stock.unique(), ticker))\n",
    "tickerList = list(news.Stock.map(stockDict))\n",
    "news.insert(loc = 0, column = 'Ticker', value = tickerList)\n",
    "\n",
    "#To datetime\n",
    "news.Date = pd.to_datetime(news['Date'])\n",
    "news.Date = news.Date.dt.strftime('%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "\n",
    "\n",
    "#Tokenize\n",
    "def newsToken(i):\n",
    "    for i in news.Content_Clean: \n",
    "         yield(gensim.utils.simple_preprocess(str(i), deacc=True)) \n",
    " \n",
    "    \n",
    "#Remove stopwords\n",
    "def newsStopword(content):   \n",
    "    stopWords = stopwords.words('english') \n",
    "    stopWords.extend(['reuters', 'january', 'february', 'march', 'april', 'may', 'june', \n",
    "                      'july', 'august', 'september', 'october', 'november', 'devember', \n",
    "                      'london', 'summary', 'new york','bengaluru', 'america'])\n",
    "    keepWords = ['up','down','against', 'above','below','off','over','further','no','not','only']\n",
    "    stopWords = list(set(stopWords) - set(keepWords))\n",
    "    return [[i for i in simple_preprocess(str(doc)) \n",
    "             if i not in stopWords and len(i) >=1 ] for doc in content] \n",
    "\n",
    "    \n",
    "#Lemmatization\n",
    "def newsLemmatization(content, allowed_postags=['NOUN', 'PROPN', 'VERB', 'ADP', 'ADJ']):  \n",
    "    nlp = spacy.load(\"en_core_web_sm\")  #Using spaCy library, loading English package here\n",
    "    texts_out = []\n",
    "    for i in content: #Operation for each news doc\n",
    "        doc = nlp(\" \".join(i)) #Join the words together first for lemma analysis\n",
    "        #Get the lemma for each word\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags]) \n",
    "    return texts_out\n",
    "\n",
    "\n",
    "    \n",
    "#Execute step by step\n",
    "matrix1 = list(newsToken(news.Content_Clean))  \n",
    "matrix2 = newsLemmatization(matrix1)\n",
    "matrix3 = newsStopword(matrix2) \n",
    "\n",
    "#Insert columns for tokenized content\n",
    "news.insert(loc = 7 , column = 'Content_Clean_Token', value = matrix3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7ca17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Clean</th>\n",
       "      <th>Content_Clean_Token</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>02/07/2021 21:31:00</td>\n",
       "      <td>AMD directors dodge shareholder derivative sui...</td>\n",
       "      <td>Jody Godoy</td>\n",
       "      <td>Summary Related documents Shareholder showed n...</td>\n",
       "      <td>related document shareholder show basis skip d...</td>\n",
       "      <td>['related' 'document' 'shareholder' 'show' 'ba...</td>\n",
       "      <td>https://www.reuters.com/legal/litigation/amd-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>27/04/2021 20:27:00</td>\n",
       "      <td>AMD lifts revenue forecast, CEO says supply ch...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>April 27 (Reuters) - Advanced Micro Devices In...</td>\n",
       "      <td>advance micro devices inc amd raise annual rev...</td>\n",
       "      <td>['advance' 'micro' 'devices' 'inc' 'amd' 'rais...</td>\n",
       "      <td>https://www.reuters.com/technology/amd-lifts-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>25/05/2021 13:00:00</td>\n",
       "      <td>Oracle launches Arm-based cloud computing serv...</td>\n",
       "      <td>Stephen Nellis</td>\n",
       "      <td>May 25 (Reuters) - Oracle Corp  (ORCL.N)  on T...</td>\n",
       "      <td>oracle corp orcl tuesday launch cloud computin...</td>\n",
       "      <td>['oracle' 'corp' 'orcl' 'tuesday' 'launch' 'cl...</td>\n",
       "      <td>https://www.reuters.com/technology/oracle-laun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>29/11/2021 20:18:00</td>\n",
       "      <td>Wall Street regains some ground after virus pu...</td>\n",
       "      <td>Ambar Warrick</td>\n",
       "      <td>Summary Companies (Updates prices, adds commen...</td>\n",
       "      <td>company update price add commentary change byl...</td>\n",
       "      <td>['company' 'update' 'price' 'add' 'commentary'...</td>\n",
       "      <td>https://www.reuters.com/markets/europe/wall-st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>21/09/2021 06:02:00</td>\n",
       "      <td>Novartis buys gene therapy firm Arctos Medical...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>ZURICH, Sept 21 (Reuters) - Swiss drugmaker No...</td>\n",
       "      <td>zurich sept swiss drugmaker novartis novn say ...</td>\n",
       "      <td>['zurich' 'sept' 'swiss' 'drugmaker' 'novartis...</td>\n",
       "      <td>https://www.reuters.com/business/healthcare-ph...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker Stock                 Date  \\\n",
       "0    AMD   AMD  02/07/2021 21:31:00   \n",
       "1    AMD   AMD  27/04/2021 20:27:00   \n",
       "2    AMD   AMD  25/05/2021 13:00:00   \n",
       "3    AMD   AMD  29/11/2021 20:18:00   \n",
       "4    AMD   AMD  21/09/2021 06:02:00   \n",
       "\n",
       "                                               Title          Author  \\\n",
       "0  AMD directors dodge shareholder derivative sui...      Jody Godoy   \n",
       "1  AMD lifts revenue forecast, CEO says supply ch...         Reuters   \n",
       "2  Oracle launches Arm-based cloud computing serv...  Stephen Nellis   \n",
       "3  Wall Street regains some ground after virus pu...   Ambar Warrick   \n",
       "4  Novartis buys gene therapy firm Arctos Medical...         Reuters   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Summary Related documents Shareholder showed n...   \n",
       "1  April 27 (Reuters) - Advanced Micro Devices In...   \n",
       "2  May 25 (Reuters) - Oracle Corp  (ORCL.N)  on T...   \n",
       "3  Summary Companies (Updates prices, adds commen...   \n",
       "4  ZURICH, Sept 21 (Reuters) - Swiss drugmaker No...   \n",
       "\n",
       "                                       Content_Clean  \\\n",
       "0  related document shareholder show basis skip d...   \n",
       "1  advance micro devices inc amd raise annual rev...   \n",
       "2  oracle corp orcl tuesday launch cloud computin...   \n",
       "3  company update price add commentary change byl...   \n",
       "4  zurich sept swiss drugmaker novartis novn say ...   \n",
       "\n",
       "                                 Content_Clean_Token  \\\n",
       "0  ['related' 'document' 'shareholder' 'show' 'ba...   \n",
       "1  ['advance' 'micro' 'devices' 'inc' 'amd' 'rais...   \n",
       "2  ['oracle' 'corp' 'orcl' 'tuesday' 'launch' 'cl...   \n",
       "3  ['company' 'update' 'price' 'add' 'commentary'...   \n",
       "4  ['zurich' 'sept' 'swiss' 'drugmaker' 'novartis...   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.reuters.com/legal/litigation/amd-d...  \n",
       "1  https://www.reuters.com/technology/amd-lifts-a...  \n",
       "2  https://www.reuters.com/technology/oracle-laun...  \n",
       "3  https://www.reuters.com/markets/europe/wall-st...  \n",
       "4  https://www.reuters.com/business/healthcare-ph...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ca4e01",
   "metadata": {},
   "source": [
    "### 4.2 Tweets Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68597d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge all stock csv\n",
    "df = pd.DataFrame()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    df1 = pd.read_csv(file)\n",
    "    df = pd.concat([df, df1])\n",
    "    \n",
    "#To datetime\n",
    "df.date = pd.to_datetime(df['date'])\n",
    "df.date = df.date.dt.strftime('%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "\n",
    "def _1_TextprocessTweet(tweet):\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #Remove www.* or https?://*\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',tweet)\n",
    "    #Remove @username \n",
    "    tweet = re.sub('@[^\\s]+',' ',tweet)\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #Remove newlines\n",
    "    tweet = tweet.strip('\\n')\n",
    "\n",
    "    #Remove all username mentions, hashtags and ticker tags\n",
    "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)|(\\$[A-Za-z0-9]+)\", \" \", tweet).split())\n",
    "    \n",
    "    #replace emoji with text\n",
    "    tweet = emoji.demojize(tweet)\n",
    "    tweet = tweet.replace(\":\",\" \")\n",
    "    tweet = ' '.join(tweet.split())\n",
    "    tweet = tweet.replace('_',\" \")\n",
    "    #tweet = word_tokenize(tweet)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "#Tokenize\n",
    "def _2_Tokenize_Stopword(tweet):  \n",
    "\n",
    "    #remove punctuation\n",
    "    tweet = tweet.replace('\\'','')\n",
    "    tweet = re.sub('[%s]' % re.escape(string.punctuation), ' ', tweet) \n",
    "\n",
    "    tokens = [w for w in word_tokenize(tweet) if w.isalpha()] \n",
    "    stopWords = stopwords.words('english') \n",
    "    keepWords = ['up','down','against', 'above','below','off','over','further','no','not','only']\n",
    "    stopWords = list(set(stopWords) - set(keepWords))\n",
    "    stopWords.extend(['amzn', 'aapl', 'msft', 'tsla', 'atvi', 'nvda', 'fb', 'uber', 'ma', 'amd', 'intc', 'nflx'])\n",
    "\n",
    "    tweet = [t for t in tokens if t not in stopWords]\n",
    "    return tweet\n",
    "\n",
    "\n",
    "#Lemmatization\n",
    "def _3_Lemmatization(tweet, allowed_postags=['NOUN', 'PROPN', 'VERB', 'ADP','ADJ']):  \n",
    "    nlp = spacy.load(\"en_core_web_sm\")  #Using spaCy library, loading English package here\n",
    "    doc = nlp(\" \".join(tweet))\n",
    "    tweet = [token.lemma_ for token in doc if token.pos_ in allowed_postags]\n",
    "    return tweet\n",
    "\n",
    "\n",
    "#Populate various processed columns\n",
    "df['content_clean'] = df['content'].apply(_1_TextprocessTweet)\n",
    "df['content_tokenized'] = df['content_clean'].apply(_2_Tokenize_Stopword)\n",
    "\n",
    "\n",
    "#Using concurrency to speed up the lemmatization function\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor: \n",
    "    df['content_lemmatized'] = list(executor.map(_3_Lemmatization, df['content_tokenized']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d829447c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>content</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>verified</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>listedCount</th>\n",
       "      <th>mediaCount</th>\n",
       "      <th>ticker</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>content_tokenized</th>\n",
       "      <th>content_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28/02/2022 22:39:16</td>\n",
       "      <td>1498427612665987078</td>\n",
       "      <td>$SPY #SPY #QQQ $QQQ $UVXY #UVXY $AMC #AMC $AAP...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>279</td>\n",
       "      <td>1026</td>\n",
       "      <td>4</td>\n",
       "      <td>833</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>final liquidity pump underway. this is it. the...</td>\n",
       "      <td>['final', 'liquidity', 'pump', 'underway', 'su...</td>\n",
       "      <td>['final', 'liquidity', 'pump', 'underway', 'su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28/02/2022 21:42:08</td>\n",
       "      <td>1498413233698443272</td>\n",
       "      <td>$AAPL held Premarket high for a bit in morning...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>258</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>held premarket high for a bit in morning befor...</td>\n",
       "      <td>['held', 'premarket', 'high', 'bit', 'morning'...</td>\n",
       "      <td>['hold', 'premarket', 'high', 'bit', 'morning'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28/02/2022 21:30:00</td>\n",
       "      <td>1498410179972399105</td>\n",
       "      <td>$AAPL closed today at $165.12. If you bought 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>closed today at .12. if you bought 1 share of ...</td>\n",
       "      <td>['closed', 'today', 'bought', 'share', 'closin...</td>\n",
       "      <td>['close', 'today', 'buy', 'share', 'closing', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28/02/2022 10:28:15</td>\n",
       "      <td>1498243644431732743</td>\n",
       "      <td>$SPY #SPY #QQQ $QQQ $AMC #AMC $AAPL #AAPL $GME...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>279</td>\n",
       "      <td>1026</td>\n",
       "      <td>4</td>\n",
       "      <td>833</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>levels still valid and all levels will be rete...</td>\n",
       "      <td>['levels', 'still', 'valid', 'levels', 'retest...</td>\n",
       "      <td>['level', 'valid', 'level', 'reteste', 'up', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28/02/2022 04:57:58</td>\n",
       "      <td>1498160526311915520</td>\n",
       "      <td>$AAPL Weekly. #AAPL formed a hammer candlestic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>18591</td>\n",
       "      <td>494</td>\n",
       "      <td>520</td>\n",
       "      <td>8381</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>weekly. formed a hammer candlestick last week,...</td>\n",
       "      <td>['weekly', 'formed', 'hammer', 'candlestick', ...</td>\n",
       "      <td>['weekly', 'form', 'hammer', 'candlestick', 'l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date             tweet_id  \\\n",
       "0  28/02/2022 22:39:16  1498427612665987078   \n",
       "1  28/02/2022 21:42:08  1498413233698443272   \n",
       "2  28/02/2022 21:30:00  1498410179972399105   \n",
       "3  28/02/2022 10:28:15  1498243644431732743   \n",
       "4  28/02/2022 04:57:58  1498160526311915520   \n",
       "\n",
       "                                             content  replyCount  \\\n",
       "0  $SPY #SPY #QQQ $QQQ $UVXY #UVXY $AMC #AMC $AAP...           0   \n",
       "1  $AAPL held Premarket high for a bit in morning...           0   \n",
       "2  $AAPL closed today at $165.12. If you bought 1...           0   \n",
       "3  $SPY #SPY #QQQ $QQQ $AMC #AMC $AAPL #AAPL $GME...           0   \n",
       "4  $AAPL Weekly. #AAPL formed a hammer candlestic...           0   \n",
       "\n",
       "   retweetCount  likeCount  quoteCount  verified  followersCount  \\\n",
       "0             1          2           0     False             279   \n",
       "1             0          0           0     False              60   \n",
       "2             0          0           0     False              50   \n",
       "3             1          2           0     False             279   \n",
       "4             0         12           0     False           18591   \n",
       "\n",
       "   friendsCount  listedCount  mediaCount ticker  \\\n",
       "0          1026            4         833   AAPL   \n",
       "1           258            4          32   AAPL   \n",
       "2            11            0           1   AAPL   \n",
       "3          1026            4         833   AAPL   \n",
       "4           494          520        8381   AAPL   \n",
       "\n",
       "                                       content_clean  \\\n",
       "0  final liquidity pump underway. this is it. the...   \n",
       "1  held premarket high for a bit in morning befor...   \n",
       "2  closed today at .12. if you bought 1 share of ...   \n",
       "3  levels still valid and all levels will be rete...   \n",
       "4  weekly. formed a hammer candlestick last week,...   \n",
       "\n",
       "                                   content_tokenized  \\\n",
       "0  ['final', 'liquidity', 'pump', 'underway', 'su...   \n",
       "1  ['held', 'premarket', 'high', 'bit', 'morning'...   \n",
       "2  ['closed', 'today', 'bought', 'share', 'closin...   \n",
       "3  ['levels', 'still', 'valid', 'levels', 'retest...   \n",
       "4  ['weekly', 'formed', 'hammer', 'candlestick', ...   \n",
       "\n",
       "                                  content_lemmatized  \n",
       "0  ['final', 'liquidity', 'pump', 'underway', 'su...  \n",
       "1  ['hold', 'premarket', 'high', 'bit', 'morning'...  \n",
       "2  ['close', 'today', 'buy', 'share', 'closing', ...  \n",
       "3  ['level', 'valid', 'level', 'reteste', 'up', '...  \n",
       "4  ['weekly', 'form', 'hammer', 'candlestick', 'l...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca73b60",
   "metadata": {},
   "source": [
    "## 5. Sentiment Analysis | News Data | Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474a458",
   "metadata": {},
   "source": [
    "### 5.1 Library Flair (Using sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af9b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flair is sentence based\n",
    "#So we use sentence instead of token for this package\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "news = news.dropna()\n",
    "\n",
    "def flairClean(row):\n",
    "    rows = row.replace('Register now for FREE unlimited access to Reuters.com Register ', '').replace(\n",
    "        ' Our Standards:  The Thomson Reuters Trust Principles.', '') \n",
    "\n",
    "    rows = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ', rows)\n",
    "    rows = re.sub('@[^\\s]+',' ', rows)\n",
    "    rows = re.sub('[\\'\"!+?=)(*><&/;:$%\\n]', ' ', rows)\n",
    "    rows = re.sub('[\\s]+', ' ', rows)\n",
    "    return rows\n",
    "\n",
    "\n",
    "def sentence(paragraph):\n",
    "    sentences = [elm for elm in split_single(paragraph)]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def cleanEmpty(sentence):\n",
    "    \n",
    "    a = [x for x in sentence if x]\n",
    "    \n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "def flair(sentence):\n",
    "    \n",
    "    poslen = 0\n",
    "    neglen = 0 \n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    \n",
    "    for i in sentence:\n",
    "        text = Sentence(i)\n",
    "        classifier.predict(text)\n",
    "               \n",
    "        value = text.labels[0].to_dict()['value'] \n",
    "        if value == 'POSITIVE':\n",
    "            pos += text.labels[0].to_dict()['confidence']\n",
    "            poslen += 1\n",
    "        else:\n",
    "            neg += -(text.labels[0].to_dict()['confidence'])\n",
    "            neglen += 1\n",
    "        \n",
    "    if poslen == 0 and neglen == 0:\n",
    "        score = 0            \n",
    "    elif neglen == 0:\n",
    "        score = pos/poslen\n",
    "    elif poslen == 0:\n",
    "        score = neg/neglen\n",
    "    else:\n",
    "        score = (pos+neg)/(pos+abs(neg))\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "news['Sentiment_Flair'] = news['Content'].apply(flairClean).apply(sentence).apply(flair)\n",
    "df['Sentiment_Flair'] = news['content_clean'].apply(flairClean).apply(sentence).apply(cleanEmpty).apply(flair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e0d61",
   "metadata": {},
   "source": [
    "### 5.2 Library Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355be17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def afinn(text):\n",
    "    afinn = Afinn(language = 'en') \n",
    "    poslen = 0\n",
    "    neglen = 0 \n",
    "    pos = 0\n",
    "    neg = 0\n",
    "      \n",
    "    for i in text:\n",
    "        if afinn.score(i) > 0:\n",
    "            pos += afinn.score(i)\n",
    "            poslen += 1\n",
    "        elif afinn.score(i) < 0:\n",
    "            neg += afinn.score(i)\n",
    "            neglen += 1\n",
    "\n",
    "    if poslen == 0 and neglen == 0:\n",
    "        score = 0            \n",
    "    elif neglen == 0:\n",
    "        score = (pos/poslen)/5\n",
    "    elif poslen == 0:\n",
    "        score = (neg/neglen)/5\n",
    "    else:\n",
    "        score = (pos+neg)/(pos+abs(neg))\n",
    "    \n",
    "    return score\n",
    "    \n",
    "    \n",
    "df['content_lemmatized'].apply(afinn)\n",
    "news['Content_Clean_Token'].apply(afinn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c5af45",
   "metadata": {},
   "source": [
    "### 5.3 Library Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6723c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader(text):\n",
    "    new_words = {\n",
    "    'fire': 4.0,\n",
    "    'decreasing': -4.0,\n",
    "    'increasing': 4.0,\n",
    "    'decrease': -4.0,\n",
    "    'increase': 4.0,\n",
    "    'rocket':4.0,\n",
    "    'up':4.0,\n",
    "    'down':-4.0,\n",
    "    'bull':4.0,\n",
    "    'bear':-4.0\n",
    "    }\n",
    "\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sia.lexicon.update(new_words)\n",
    "    \n",
    "    poslen = 0\n",
    "    neglen = 0 \n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    \n",
    "    for i in text:\n",
    "        if sia.polarity_scores(i)['compound'] > 0:\n",
    "            pos += sia.polarity_scores(i)['compound']\n",
    "            poslen += 1\n",
    "        elif sia.polarity_scores(i)['compound'] < 0:\n",
    "            neg += sia.polarity_scores(i)['compound']\n",
    "            neglen += 1\n",
    "                       \n",
    "    if poslen == 0 and neglen == 0:\n",
    "        score = 0            \n",
    "    elif neglen == 0:\n",
    "        score = (pos/poslen)\n",
    "    elif poslen == 0:\n",
    "        score = (neg/neglen)\n",
    "    else:\n",
    "        score = (pos+neg)/(pos+abs(neg))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffc946b",
   "metadata": {},
   "source": [
    "### 5.4 Library TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf766fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textblob(text):\n",
    "    poslen = 0\n",
    "    neglen = 0 \n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    \n",
    "    for i in text:\n",
    "        if TextBlob(i).sentiment.polarity > 0:\n",
    "            pos += TextBlob(i).sentiment.polarity\n",
    "            poslen += 1\n",
    "        elif TextBlob(i).sentiment.polarity < 0:\n",
    "            neg += TextBlob(i).sentiment.polarity\n",
    "            neglen += 1\n",
    "\n",
    "    if poslen == 0 and neglen == 0:\n",
    "        score = 0            \n",
    "    elif neglen == 0:\n",
    "        score = (pos/poslen)\n",
    "    elif poslen == 0:\n",
    "        score = (neg/neglen)\n",
    "    else:\n",
    "        score = (pos+neg)/(pos+abs(neg))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295c765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Clean</th>\n",
       "      <th>Content_Clean_Token</th>\n",
       "      <th>Url</th>\n",
       "      <th>Sentiment_Flair</th>\n",
       "      <th>Sentiment_Afinn</th>\n",
       "      <th>Sentiment_Vader</th>\n",
       "      <th>Sentiment_TextBlob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>02/07/2021 21:31:00</td>\n",
       "      <td>AMD directors dodge shareholder derivative sui...</td>\n",
       "      <td>Jody Godoy</td>\n",
       "      <td>Summary Related documents Shareholder showed n...</td>\n",
       "      <td>related document shareholder show basis skip d...</td>\n",
       "      <td>['related' 'document' 'shareholder' 'show' 'ba...</td>\n",
       "      <td>https://www.reuters.com/legal/litigation/amd-d...</td>\n",
       "      <td>-0.600430</td>\n",
       "      <td>-0.780220</td>\n",
       "      <td>-0.593653</td>\n",
       "      <td>-0.656827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>27/04/2021 20:27:00</td>\n",
       "      <td>AMD lifts revenue forecast, CEO says supply ch...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>April 27 (Reuters) - Advanced Micro Devices In...</td>\n",
       "      <td>advance micro devices inc amd raise annual rev...</td>\n",
       "      <td>['advance' 'micro' 'devices' 'inc' 'amd' 'rais...</td>\n",
       "      <td>https://www.reuters.com/technology/amd-lifts-a...</td>\n",
       "      <td>0.370084</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.780044</td>\n",
       "      <td>0.589689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>25/05/2021 13:00:00</td>\n",
       "      <td>Oracle launches Arm-based cloud computing serv...</td>\n",
       "      <td>Stephen Nellis</td>\n",
       "      <td>May 25 (Reuters) - Oracle Corp  (ORCL.N)  on T...</td>\n",
       "      <td>oracle corp orcl tuesday launch cloud computin...</td>\n",
       "      <td>['oracle' 'corp' 'orcl' 'tuesday' 'launch' 'cl...</td>\n",
       "      <td>https://www.reuters.com/technology/oracle-laun...</td>\n",
       "      <td>0.436454</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>-0.524692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>29/11/2021 20:18:00</td>\n",
       "      <td>Wall Street regains some ground after virus pu...</td>\n",
       "      <td>Ambar Warrick</td>\n",
       "      <td>Summary Companies (Updates prices, adds commen...</td>\n",
       "      <td>company update price add commentary change byl...</td>\n",
       "      <td>['company' 'update' 'price' 'add' 'commentary'...</td>\n",
       "      <td>https://www.reuters.com/markets/europe/wall-st...</td>\n",
       "      <td>-0.482530</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.200357</td>\n",
       "      <td>0.235957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>21/09/2021 06:02:00</td>\n",
       "      <td>Novartis buys gene therapy firm Arctos Medical...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>ZURICH, Sept 21 (Reuters) - Swiss drugmaker No...</td>\n",
       "      <td>zurich sept swiss drugmaker novartis novn say ...</td>\n",
       "      <td>['zurich' 'sept' 'swiss' 'drugmaker' 'novartis...</td>\n",
       "      <td>https://www.reuters.com/business/healthcare-ph...</td>\n",
       "      <td>0.250985</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.408526</td>\n",
       "      <td>-0.215686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker Stock                 Date  \\\n",
       "0    AMD   AMD  02/07/2021 21:31:00   \n",
       "1    AMD   AMD  27/04/2021 20:27:00   \n",
       "2    AMD   AMD  25/05/2021 13:00:00   \n",
       "3    AMD   AMD  29/11/2021 20:18:00   \n",
       "4    AMD   AMD  21/09/2021 06:02:00   \n",
       "\n",
       "                                               Title          Author  \\\n",
       "0  AMD directors dodge shareholder derivative sui...      Jody Godoy   \n",
       "1  AMD lifts revenue forecast, CEO says supply ch...         Reuters   \n",
       "2  Oracle launches Arm-based cloud computing serv...  Stephen Nellis   \n",
       "3  Wall Street regains some ground after virus pu...   Ambar Warrick   \n",
       "4  Novartis buys gene therapy firm Arctos Medical...         Reuters   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Summary Related documents Shareholder showed n...   \n",
       "1  April 27 (Reuters) - Advanced Micro Devices In...   \n",
       "2  May 25 (Reuters) - Oracle Corp  (ORCL.N)  on T...   \n",
       "3  Summary Companies (Updates prices, adds commen...   \n",
       "4  ZURICH, Sept 21 (Reuters) - Swiss drugmaker No...   \n",
       "\n",
       "                                       Content_Clean  \\\n",
       "0  related document shareholder show basis skip d...   \n",
       "1  advance micro devices inc amd raise annual rev...   \n",
       "2  oracle corp orcl tuesday launch cloud computin...   \n",
       "3  company update price add commentary change byl...   \n",
       "4  zurich sept swiss drugmaker novartis novn say ...   \n",
       "\n",
       "                                 Content_Clean_Token  \\\n",
       "0  ['related' 'document' 'shareholder' 'show' 'ba...   \n",
       "1  ['advance' 'micro' 'devices' 'inc' 'amd' 'rais...   \n",
       "2  ['oracle' 'corp' 'orcl' 'tuesday' 'launch' 'cl...   \n",
       "3  ['company' 'update' 'price' 'add' 'commentary'...   \n",
       "4  ['zurich' 'sept' 'swiss' 'drugmaker' 'novartis...   \n",
       "\n",
       "                                                 Url  Sentiment_Flair  \\\n",
       "0  https://www.reuters.com/legal/litigation/amd-d...        -0.600430   \n",
       "1  https://www.reuters.com/technology/amd-lifts-a...         0.370084   \n",
       "2  https://www.reuters.com/technology/oracle-laun...         0.436454   \n",
       "3  https://www.reuters.com/markets/europe/wall-st...        -0.482530   \n",
       "4  https://www.reuters.com/business/healthcare-ph...         0.250985   \n",
       "\n",
       "   Sentiment_Afinn  Sentiment_Vader  Sentiment_TextBlob  \n",
       "0        -0.780220        -0.593653           -0.656827  \n",
       "1         0.705882         0.780044            0.589689  \n",
       "2         0.882353         0.281721           -0.524692  \n",
       "3         0.025641         0.200357            0.235957  \n",
       "4         0.047619         0.408526           -0.215686  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4f97a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>content</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>verified</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>listedCount</th>\n",
       "      <th>mediaCount</th>\n",
       "      <th>ticker</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>content_tokenized</th>\n",
       "      <th>content_lemmatized</th>\n",
       "      <th>Sentiment_Flair</th>\n",
       "      <th>Sentiment_Afinn</th>\n",
       "      <th>Sentiment_Vader</th>\n",
       "      <th>Sentiment_TextBlob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28/02/2022 22:39:16</td>\n",
       "      <td>1498427612665987078</td>\n",
       "      <td>$SPY #SPY #QQQ $QQQ $UVXY #UVXY $AMC #AMC $AAP...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>279</td>\n",
       "      <td>1026</td>\n",
       "      <td>4</td>\n",
       "      <td>833</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>final liquidity pump underway. this is it. the...</td>\n",
       "      <td>['final', 'liquidity', 'pump', 'underway', 'su...</td>\n",
       "      <td>['final', 'liquidity', 'pump', 'underway', 'su...</td>\n",
       "      <td>0.997430</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.440400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28/02/2022 21:42:08</td>\n",
       "      <td>1498413233698443272</td>\n",
       "      <td>$AAPL held Premarket high for a bit in morning...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>258</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>held premarket high for a bit in morning befor...</td>\n",
       "      <td>['held', 'premarket', 'high', 'bit', 'morning'...</td>\n",
       "      <td>['hold', 'premarket', 'high', 'bit', 'morning'...</td>\n",
       "      <td>0.900152</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.501733</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28/02/2022 21:30:00</td>\n",
       "      <td>1498410179972399105</td>\n",
       "      <td>$AAPL closed today at $165.12. If you bought 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>closed today at .12. if you bought 1 share of ...</td>\n",
       "      <td>['closed', 'today', 'bought', 'share', 'closin...</td>\n",
       "      <td>['close', 'today', 'buy', 'share', 'closing', ...</td>\n",
       "      <td>-0.986211</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.151741</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28/02/2022 10:28:15</td>\n",
       "      <td>1498243644431732743</td>\n",
       "      <td>$SPY #SPY #QQQ $QQQ $AMC #AMC $AAPL #AAPL $GME...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>279</td>\n",
       "      <td>1026</td>\n",
       "      <td>4</td>\n",
       "      <td>833</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>levels still valid and all levels will be rete...</td>\n",
       "      <td>['levels', 'still', 'valid', 'levels', 'retest...</td>\n",
       "      <td>['level', 'valid', 'level', 'reteste', 'up', '...</td>\n",
       "      <td>0.247874</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.187950</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28/02/2022 04:57:58</td>\n",
       "      <td>1498160526311915520</td>\n",
       "      <td>$AAPL Weekly. #AAPL formed a hammer candlestic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>18591</td>\n",
       "      <td>494</td>\n",
       "      <td>520</td>\n",
       "      <td>8381</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>weekly. formed a hammer candlestick last week,...</td>\n",
       "      <td>['weekly', 'formed', 'hammer', 'candlestick', ...</td>\n",
       "      <td>['weekly', 'form', 'hammer', 'candlestick', 'l...</td>\n",
       "      <td>-0.406989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.322088</td>\n",
       "      <td>-0.183333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date             tweet_id  \\\n",
       "0  28/02/2022 22:39:16  1498427612665987078   \n",
       "1  28/02/2022 21:42:08  1498413233698443272   \n",
       "2  28/02/2022 21:30:00  1498410179972399105   \n",
       "3  28/02/2022 10:28:15  1498243644431732743   \n",
       "4  28/02/2022 04:57:58  1498160526311915520   \n",
       "\n",
       "                                             content  replyCount  \\\n",
       "0  $SPY #SPY #QQQ $QQQ $UVXY #UVXY $AMC #AMC $AAP...           0   \n",
       "1  $AAPL held Premarket high for a bit in morning...           0   \n",
       "2  $AAPL closed today at $165.12. If you bought 1...           0   \n",
       "3  $SPY #SPY #QQQ $QQQ $AMC #AMC $AAPL #AAPL $GME...           0   \n",
       "4  $AAPL Weekly. #AAPL formed a hammer candlestic...           0   \n",
       "\n",
       "   retweetCount  likeCount  quoteCount  verified  followersCount  \\\n",
       "0             1          2           0     False             279   \n",
       "1             0          0           0     False              60   \n",
       "2             0          0           0     False              50   \n",
       "3             1          2           0     False             279   \n",
       "4             0         12           0     False           18591   \n",
       "\n",
       "   friendsCount  listedCount  mediaCount ticker  \\\n",
       "0          1026            4         833   AAPL   \n",
       "1           258            4          32   AAPL   \n",
       "2            11            0           1   AAPL   \n",
       "3          1026            4         833   AAPL   \n",
       "4           494          520        8381   AAPL   \n",
       "\n",
       "                                       content_clean  \\\n",
       "0  final liquidity pump underway. this is it. the...   \n",
       "1  held premarket high for a bit in morning befor...   \n",
       "2  closed today at .12. if you bought 1 share of ...   \n",
       "3  levels still valid and all levels will be rete...   \n",
       "4  weekly. formed a hammer candlestick last week,...   \n",
       "\n",
       "                                   content_tokenized  \\\n",
       "0  ['final', 'liquidity', 'pump', 'underway', 'su...   \n",
       "1  ['held', 'premarket', 'high', 'bit', 'morning'...   \n",
       "2  ['closed', 'today', 'bought', 'share', 'closin...   \n",
       "3  ['levels', 'still', 'valid', 'levels', 'retest...   \n",
       "4  ['weekly', 'formed', 'hammer', 'candlestick', ...   \n",
       "\n",
       "                                  content_lemmatized  Sentiment_Flair  \\\n",
       "0  ['final', 'liquidity', 'pump', 'underway', 'su...         0.997430   \n",
       "1  ['hold', 'premarket', 'high', 'bit', 'morning'...         0.900152   \n",
       "2  ['close', 'today', 'buy', 'share', 'closing', ...        -0.986211   \n",
       "3  ['level', 'valid', 'level', 'reteste', 'up', '...         0.247874   \n",
       "4  ['weekly', 'form', 'hammer', 'candlestick', 'l...        -0.406989   \n",
       "\n",
       "   Sentiment_Afinn  Sentiment_Vader  Sentiment_TextBlob  \n",
       "0             -0.6        -0.440400            0.000000  \n",
       "1              0.5         0.501733            0.380000  \n",
       "2              0.2        -0.151741            0.000000  \n",
       "3             -0.2        -0.187950            0.000000  \n",
       "4              0.0        -0.322088           -0.183333  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5052f",
   "metadata": {},
   "source": [
    "## 6. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Merging Returns Data and Sentiment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f5259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hourly\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "stocks = ['AMZN', 'AAPL', 'MSFT', 'TSLA', 'ATVI', 'NVDA', 'FB', 'UBER', 'MA', 'AMD', 'INTC', 'NFLX']\n",
    "#Read Tweets\n",
    "tweets2 = pd.read_parquet('allTWEETS_Processed.parquet')\n",
    "news2 = pd.read_parquet('News.parquet')\n",
    "\n",
    "for i in stocks:\n",
    "\n",
    "    #Read AAPL Tweets\n",
    "    tweets = tweets2.loc[tweets2['ticker'] == i]\n",
    "    news = news2.loc[news2['Ticker'] == i]\n",
    "    \n",
    "    tweets.rename(columns = {'Sentiment_Flair':'T_Sentiment_Flair','Sentiment_Afinn':'T_Sentiment_Afinn',\n",
    "                             'Sentiment_Vader':'T_Sentiment_Vader','Sentiment_TextBlob':'T_Sentiment_TextBlob'}, inplace = True)\n",
    "    \n",
    "    news.rename(columns = {'Date':'date','Sentiment_Flair':'N_Sentiment_Flair','Sentiment_Afinn':'N_Sentiment_Afinn',\n",
    "                             'Sentiment_Vader':'N_Sentiment_Vader','Sentiment_TextBlob':'N_Sentiment_TextBlob'}, inplace = True)\n",
    "    \n",
    "    #Read date and Sentiment_Flair only\n",
    "    tweets = tweets[['date', 'T_Sentiment_Flair', 'T_Sentiment_Afinn', 'T_Sentiment_Vader','T_Sentiment_TextBlob']].sort_values(by='date')\n",
    "    news = news[['date', 'N_Sentiment_Flair', 'N_Sentiment_Afinn', 'N_Sentiment_Vader','N_Sentiment_TextBlob']].sort_values(by='date')\n",
    "    \n",
    "    #Transform date to datetime\n",
    "    tweets['date'] = pd.to_datetime(tweets['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    news['date'] = pd.to_datetime(news['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    \n",
    "    #Group tweets by day taking hourly average of multiple tweet scores\n",
    "    tweets=tweets.groupby(pd.Grouper(freq='H', key='date')).mean() \n",
    "    news=news.groupby(pd.Grouper(freq='H', key='date')).mean() \n",
    "    \n",
    "    #Reset Index\n",
    "    tweets.reset_index(inplace = True)\n",
    "    news.reset_index(inplace = True)\n",
    "    \n",
    "    #Convert date to datetime again\n",
    "    tweets['date'] = pd.to_datetime(tweets['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    news['date'] = pd.to_datetime(news['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    \n",
    "    #Forward fill hours with no tweets\n",
    "    tweets = tweets.ffill(axis = 0)\n",
    "    news = news.ffill(axis = 0)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "    #Read stock price\n",
    "    stock = pd.read_csv('Hourly_Price_{}.csv'.format(i))\n",
    "    \n",
    "    #Remove %z UTC timezone from stock['Datetime']\n",
    "    stock['Datetime'] = stock['Datetime'].astype(str)\n",
    "    stock.Datetime=stock.Datetime.str[:-6]\n",
    "    \n",
    "    #Transform date to datetime\n",
    "    stock['Datetime'] = pd.to_datetime(stock['Datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    #Read date and Adj Close only\n",
    "    stock = stock[['Datetime', 'Open' ,'High', 'Low', 'Close', 'Adj Close','Volume']].sort_values(by='Datetime')\n",
    "    \n",
    "    #Standardize stock hour datetime \n",
    "    stock=stock.groupby(pd.Grouper(freq='H', key='Datetime')).mean() \n",
    "    \n",
    "    #Remove non-trading hours\n",
    "    stock.dropna(subset = ['Adj Close'], inplace=True)\n",
    "    \n",
    "    #Reset Index\n",
    "    stock.reset_index(inplace = True)\n",
    "    \n",
    "    #Calculate hourly stock returns\n",
    "    stock['Return'] = stock['Adj Close'].pct_change(1)\n",
    "    \n",
    "    #Rename and remove columns\n",
    "    stock.rename(columns = {'Datetime':'date'}, inplace = True)\n",
    "    stock = stock[['date','Return', 'Open' ,'High', 'Low', 'Close', 'Adj Close','Volume']]\n",
    "    \n",
    "    #Merge stock data and tweets data\n",
    "    df = pd.merge(stock, tweets, on=['date'])\n",
    "    df = pd.merge(df, news, on=['date'])\n",
    "    \n",
    "    df.to_parquet('HourlyReturn_{}.parquet'.format(i))\n",
    "\n",
    "\n",
    "#Daily\n",
    "\n",
    "for i in stocks:\n",
    "\n",
    "    #Read AAPL Tweets\n",
    "    tweets = tweets2.loc[tweets2['ticker'] == i]\n",
    "    news = news2.loc[news2['Ticker'] == i]\n",
    "    \n",
    "    tweets.rename(columns = {'Sentiment_Flair':'T_Sentiment_Flair','Sentiment_Afinn':'T_Sentiment_Afinn',\n",
    "                             'Sentiment_Vader':'T_Sentiment_Vader','Sentiment_TextBlob':'T_Sentiment_TextBlob'}, inplace = True)\n",
    "    \n",
    "    news.rename(columns = {'Date':'date','Sentiment_Flair':'N_Sentiment_Flair','Sentiment_Afinn':'N_Sentiment_Afinn',\n",
    "                             'Sentiment_Vader':'N_Sentiment_Vader','Sentiment_TextBlob':'N_Sentiment_TextBlob'}, inplace = True)\n",
    "    \n",
    "    #Read date and Sentiment_Flair only\n",
    "    tweets = tweets[['date', 'T_Sentiment_Flair', 'T_Sentiment_Afinn', 'T_Sentiment_Vader','T_Sentiment_TextBlob']].sort_values(by='date')\n",
    "    news = news[['date', 'N_Sentiment_Flair', 'N_Sentiment_Afinn', 'N_Sentiment_Vader','N_Sentiment_TextBlob']].sort_values(by='date')\n",
    "    \n",
    "    #Transform date to datetime\n",
    "    tweets['date'] = pd.to_datetime(tweets['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    news['date'] = pd.to_datetime(news['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    \n",
    "    #Group tweets by day taking hourly average of multiple tweet scores\n",
    "    tweets=tweets.groupby(pd.Grouper(freq='D', key='date')).mean() \n",
    "    news=news.groupby(pd.Grouper(freq='D', key='date')).mean() \n",
    "    \n",
    "    #Reset Index\n",
    "    tweets.reset_index(inplace = True)\n",
    "    news.reset_index(inplace = True)\n",
    "    \n",
    "    #Convert date to datetime again\n",
    "    tweets['date'] = pd.to_datetime(tweets['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    news['date'] = pd.to_datetime(news['date'],format = \"%d/%m/%Y %H:%M:%S\")\n",
    "    \n",
    "    #Forward fill hours with no tweets\n",
    "    tweets = tweets.ffill(axis = 0)\n",
    "    news = news.ffill(axis = 0)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "    #Read stock price\n",
    "    stock = pd.read_csv('Price_{}.csv'.format(i))\n",
    "    \n",
    "    #Remove %z UTC timezone from stock['Datetime']\n",
    "    stock = stock.reset_index()\n",
    "    \n",
    "    #Transform date to datetime\n",
    "    stock['Date'] = pd.to_datetime(stock['Date'],format = \"%Y-%m-%d\")\n",
    "    \n",
    "    #Convert datetime to date\n",
    "    stock['Date'] = pd.to_datetime(stock['Date'].dt.date)\n",
    "    \n",
    "    #Read date and Adj Close only\n",
    "    stock = stock[['Date', 'Open' ,'High', 'Low', 'Close', 'Adj Close','Volume', 'Ticker']].sort_values(by='Date')\n",
    "    \n",
    "    #Calculate daily stock returns\n",
    "    stock['Return'] = stock['Adj Close'].pct_change(1)\n",
    "    \n",
    "    #Rename and remove columns\n",
    "    stock.rename(columns = {'Date':'date'}, inplace = True)\n",
    "    stock = stock[['date','Return', 'Open' ,'High', 'Low', 'Close', 'Adj Close','Volume', 'Ticker']]\n",
    "    \n",
    "    #Merge stock data and tweets data\n",
    "    df = pd.merge(stock, tweets, on=['date'])\n",
    "    df = pd.merge(df, news, on=['date'])\n",
    "    \n",
    "    df.to_parquet('DailyReturn_{}.parquet'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e70dd5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Return</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>T_Sentiment_Flair</th>\n",
       "      <th>T_Sentiment_Afinn</th>\n",
       "      <th>T_Sentiment_Vader</th>\n",
       "      <th>T_Sentiment_TextBlob</th>\n",
       "      <th>N_Sentiment_Flair</th>\n",
       "      <th>N_Sentiment_Afinn</th>\n",
       "      <th>N_Sentiment_Vader</th>\n",
       "      <th>N_Sentiment_TextBlob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>152.830002</td>\n",
       "      <td>154.979996</td>\n",
       "      <td>152.339996</td>\n",
       "      <td>152.509995</td>\n",
       "      <td>152.093964</td>\n",
       "      <td>80313700</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.439025</td>\n",
       "      <td>0.075238</td>\n",
       "      <td>0.129183</td>\n",
       "      <td>0.261108</td>\n",
       "      <td>-0.451613</td>\n",
       "      <td>0.101139</td>\n",
       "      <td>0.166658</td>\n",
       "      <td>0.323046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>153.869995</td>\n",
       "      <td>154.720001</td>\n",
       "      <td>152.399994</td>\n",
       "      <td>153.649994</td>\n",
       "      <td>153.230850</td>\n",
       "      <td>71115500</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.389312</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.239850</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>-0.375664</td>\n",
       "      <td>0.022325</td>\n",
       "      <td>0.152422</td>\n",
       "      <td>0.300089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>153.759995</td>\n",
       "      <td>154.630005</td>\n",
       "      <td>153.089996</td>\n",
       "      <td>154.300003</td>\n",
       "      <td>153.879089</td>\n",
       "      <td>57808700</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.321581</td>\n",
       "      <td>0.124074</td>\n",
       "      <td>0.056036</td>\n",
       "      <td>0.042972</td>\n",
       "      <td>-0.465355</td>\n",
       "      <td>-0.021327</td>\n",
       "      <td>0.042717</td>\n",
       "      <td>-0.135096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-07</td>\n",
       "      <td>0.015489</td>\n",
       "      <td>154.970001</td>\n",
       "      <td>157.259995</td>\n",
       "      <td>154.389999</td>\n",
       "      <td>156.690002</td>\n",
       "      <td>156.262573</td>\n",
       "      <td>82278300</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.575571</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.107470</td>\n",
       "      <td>-0.007832</td>\n",
       "      <td>-0.310510</td>\n",
       "      <td>0.341669</td>\n",
       "      <td>0.350883</td>\n",
       "      <td>0.272359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-08</td>\n",
       "      <td>-0.010084</td>\n",
       "      <td>156.979996</td>\n",
       "      <td>157.039993</td>\n",
       "      <td>153.979996</td>\n",
       "      <td>155.110001</td>\n",
       "      <td>154.686874</td>\n",
       "      <td>74420200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.504929</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>-0.115833</td>\n",
       "      <td>-0.263752</td>\n",
       "      <td>0.302215</td>\n",
       "      <td>0.449849</td>\n",
       "      <td>0.297079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    Return        Open        High         Low       Close  \\\n",
       "0 2021-09-01  0.004479  152.830002  154.979996  152.339996  152.509995   \n",
       "1 2021-09-02  0.007475  153.869995  154.720001  152.399994  153.649994   \n",
       "2 2021-09-03  0.004230  153.759995  154.630005  153.089996  154.300003   \n",
       "3 2021-09-07  0.015489  154.970001  157.259995  154.389999  156.690002   \n",
       "4 2021-09-08 -0.010084  156.979996  157.039993  153.979996  155.110001   \n",
       "\n",
       "    Adj Close    Volume Ticker  T_Sentiment_Flair  T_Sentiment_Afinn  \\\n",
       "0  152.093964  80313700   AAPL           0.439025           0.075238   \n",
       "1  153.230850  71115500   AAPL           0.389312           0.150000   \n",
       "2  153.879089  57808700   AAPL           0.321581           0.124074   \n",
       "3  156.262573  82278300   AAPL           0.575571           0.002564   \n",
       "4  154.686874  74420200   AAPL           0.504929           0.011111   \n",
       "\n",
       "   T_Sentiment_Vader  T_Sentiment_TextBlob  N_Sentiment_Flair  \\\n",
       "0           0.129183              0.261108          -0.451613   \n",
       "1           0.239850              0.012037          -0.375664   \n",
       "2           0.056036              0.042972          -0.465355   \n",
       "3           0.107470             -0.007832          -0.310510   \n",
       "4           0.053732             -0.115833          -0.263752   \n",
       "\n",
       "   N_Sentiment_Afinn  N_Sentiment_Vader  N_Sentiment_TextBlob  \n",
       "0           0.101139           0.166658              0.323046  \n",
       "1           0.022325           0.152422              0.300089  \n",
       "2          -0.021327           0.042717             -0.135096  \n",
       "3           0.341669           0.350883              0.272359  \n",
       "4           0.302215           0.449849              0.297079  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl = pd.read_parquet('DailyReturn_AAPL.parquet')\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63613a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = ['T', 'N']\n",
    "time1 = ['Daily', 'Hourly']\n",
    "mod1 = ['Flair', 'TextBlob', 'Vader', 'Afinn']\n",
    "\n",
    "def reg (data, time, mod):\n",
    "    stocks1 = ['AMZN', 'AAPL', 'MSFT', 'TSLA', 'NVDA', 'FB', 'UBER', 'NFLX']\n",
    "    \n",
    "    for i in stocks1:\n",
    "        test = pd.read_parquet('{}Return_{}.parquet'.format(time,i))\n",
    "        \n",
    "\n",
    "        test = test[['Return', '{}_Sentiment_{}'.format(data, mod)]]\n",
    "        test['{}_Sentiment_{}_Lag1'.format(data, mod)] = test['{}_Sentiment_{}'.format(data, mod)].shift(1)\n",
    "        test['{}_Sentiment_{}_Lag2'.format(data, mod)] = test['{}_Sentiment_{}'.format(data, mod)].shift(2)\n",
    "        test['{}_Sentiment_{}_Lag3'.format(data, mod)] = test['{}_Sentiment_{}'.format(data, mod)].shift(3)\n",
    "        test['{}_Sentiment_{}_Lag6'.format(data, mod)] = test['{}_Sentiment_{}'.format(data, mod)].shift(6)\n",
    "\n",
    "        \n",
    "        all_columns = \"+\".join(np.delete(test.columns, [0]))\n",
    "        my_formula = \"Return~\" + all_columns\n",
    "        \n",
    "        coef = smf.ols(formula = my_formula, data = test).fit().params\n",
    "        pval = smf.ols(formula = my_formula, data = test).fit().pvalues\n",
    "        table = pd.concat({'Coef': coef,'P-value': pval}, axis=1)\n",
    "        table['Significance'] = np.where(table['P-value'] <= 0.05, 'Yes', 'No')\n",
    "        table['Correlation'] = np.where((table['Coef'] >0 ) & (table['Significance'] =='Yes' ), 'Postive', 'Negative/No')\n",
    "        print (i)\n",
    "        print (table)       \n",
    "    \n",
    "    \n",
    "#Regression results for news\n",
    "for i in mod1:  \n",
    "     reg('N', 'Hourly', i)\n",
    "for i in mod1:  \n",
    "     reg('N', 'Daily', i)\n",
    "     \n",
    "\n",
    "#Regression results for tweets\n",
    "for i in mod1:  \n",
    "     reg('T', 'Hourly', i)\n",
    "for i in mod1:  \n",
    "     reg('T', 'Daily', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a1e610e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdasd\n",
      "asdasd dsadasd\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1073ec64",
   "metadata": {},
   "source": [
    "## 7. Trading Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170a9cc",
   "metadata": {},
   "source": [
    "### 7.1 Strategy 1: 0.2 buy sell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690d740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('DailyReturn_AMZN.parquet')\n",
    "df_close = df['Close'].tolist()\n",
    "df_adj_close = df['Adj Close'].tolist()\n",
    "df_ticker = df['Ticker'].tolist()\n",
    "T_Sentiment_Flair = df['T_Sentiment_Flair'].tolist()\n",
    "T_Sentiment_Afinn = df['T_Sentiment_Afinn'].tolist()\n",
    "T_Sentiment_Vader = df['T_Sentiment_Vader'].tolist()\n",
    "T_Sentiment_TextBlob = df['T_Sentiment_TextBlob'].tolist()\n",
    "\n",
    "\n",
    "def change_buy_sell():\n",
    "    initial= 1000000\n",
    "    #changing initial\n",
    "    cinitial=1000000\n",
    "    amount=0\n",
    "    buyprice = 0\n",
    "    sellprice = 0\n",
    "    Ireturn = 0\n",
    "    i=0\n",
    "    Return = []\n",
    "    for i in range(len(sscore)-1):\n",
    "            #buy_action\n",
    "             if(sscore[i+1]-sscore[i])>=0.2:\n",
    "                 buyprice = stock_price[i+1]\n",
    "                 amount = cinitial/buyprice\n",
    "                 buyprice = amount * buyprice\n",
    "            #sell_action \n",
    "             elif(sscore[i+1]-sscore[i]) <=-0.2:  \n",
    "                 sellprice = stock_price[i+1]\n",
    "                 sellprice = (amount*sellprice)\n",
    "                 if buyprice != 0:\n",
    "                     Ireturn = sellprice-buyprice \n",
    "                     Return.append(Ireturn)\n",
    "                     buyprice = sellprice = amount = 0\n",
    "                     cinitial = Ireturn + cinitial \n",
    "    return  (sum(Return)/initial)*100\n",
    "\n",
    "\n",
    "winner= None\n",
    "winning_score=-1000000000000\n",
    "change_buy_sell_avg=0\n",
    "\n",
    "sscore= T_Sentiment_Flair\n",
    "stock_price= df_close\n",
    "print('<<Flair>>   G/L',change_buy_sell(),'%')\n",
    "change_buy_sell_avg+=change_buy_sell()\n",
    "if change_buy_sell() >= winning_score:\n",
    "    winner = 'Flair'\n",
    "    winning_score=change_buy_sell()\n",
    "\n",
    "sscore= T_Sentiment_Afinn\n",
    "stock_price= df_close\n",
    "print('<<Afinn>>    G/L',change_buy_sell(),'%')\n",
    "change_buy_sell_avg+=change_buy_sell()\n",
    "if change_buy_sell() >= winning_score:\n",
    "    winner = 'Flair'\n",
    "    winning_score=change_buy_sell()\n",
    "    \n",
    "sscore= T_Sentiment_Vader\n",
    "stock_price= df_close\n",
    "print('<<Vader>>    G/L',change_buy_sell(),'%')\n",
    "change_buy_sell_avg+=change_buy_sell()\n",
    "if change_buy_sell() >= winning_score:\n",
    "    winner = 'Flair'\n",
    "    winning_score=change_buy_sell()\n",
    "    \n",
    "sscore= T_Sentiment_TextBlob\n",
    "stock_price= df_close\n",
    "print('<<TextBlob>>    G/L',change_buy_sell(),'%')\n",
    "change_buy_sell_avg+=change_buy_sell()\n",
    "if change_buy_sell() >= winning_score:\n",
    "    winner = 'Flair'\n",
    "    winning_score=change_buy_sell()\n",
    "    \n",
    "print('   [[',winner,winning_score,'%',']]')\n",
    "print('                                          Strategy[0.2 BS] avg',change_buy_sell_avg/4,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642444cb",
   "metadata": {},
   "source": [
    "### 7.2 Strategy 2: Cross Trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c83d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_trade():\n",
    "    amount2=0\n",
    "    inti=1000000\n",
    "    buyprice = 0\n",
    "    sellprice = 0\n",
    "    Ireturn = 0\n",
    "    i=0\n",
    "    Return = []\n",
    "    for i in range(21,len(sscore)-1):\n",
    "        fl=sum(sscore[i-2:i])/2\n",
    "        sl=sum(sscore[i-4:i])/4\n",
    "        cfl=sum(sscore[i-3:i-1])/2\n",
    "        csl=sum(sscore[i-5:i-1])/4\n",
    "        newcom=fl-sl\n",
    "        #newcompare\n",
    "        oldcom=cfl-csl\n",
    "        #oldcompare\n",
    "        if sl-fl >=0 and oldcom*newcom<=0: \n",
    "            buyprice = stock_price[i+1]\n",
    "            amount2 = inti/buyprice\n",
    "            buyprice = amount2 * buyprice\n",
    "       #sell_action \n",
    "        elif sl-fl <=0 and oldcom*newcom<=0:  \n",
    "           sellprice = stock_price[i+1]\n",
    "           sellprice = (amount2*sellprice)\n",
    "           if buyprice != 0:\n",
    "               Ireturn = sellprice-buyprice \n",
    "               Return.append(Ireturn)\n",
    "               buyprice = sellprice = amount2 = 0\n",
    "               inti = Ireturn + inti\n",
    "    return  ((sum(Return))/1000000)*100\n",
    "\n",
    "#fastline  #slowline\n",
    "\n",
    "winner= None\n",
    "winning_score=-1000000000000000\n",
    "cross_avg=0\n",
    "\n",
    "sscore= T_Sentiment_Flair\n",
    "stock_price= df_close\n",
    "print('<<Flair>>   G/L:',cross_trade(),'%')\n",
    "cross_avg+=cross_trade()\n",
    "if cross_trade() >= winning_score:\n",
    "    winner = 'Flair'\n",
    "    winning_score=cross_trade()\n",
    "\n",
    "sscore= T_Sentiment_Afinn\n",
    "stock_price= df_close\n",
    "print('<<Afinn>>   G/L:',cross_trade(),'%')\n",
    "cross_avg+=cross_trade()\n",
    "if cross_trade() >= winning_score:\n",
    "    winner = 'Afinn'\n",
    "    winning_score=cross_trade()\n",
    "\n",
    "sscore= T_Sentiment_Vader\n",
    "stock_price= df_close\n",
    "print('<<Vader>>   G/L:',cross_trade(),'%')\n",
    "cross_avg+=cross_trade()\n",
    "if cross_trade() >= winning_score:\n",
    "    winner = 'Vader'\n",
    "    winning_score=cross_trade()\n",
    "\n",
    "sscore= T_Sentiment_TextBlob\n",
    "stock_price= df_close\n",
    "print('<<TextBlob>>   G/L:',cross_trade(),'%')\n",
    "cross_avg+=cross_trade()\n",
    "if cross_trade() >= winning_score:\n",
    "    winner = 'TextBlob'\n",
    "    winning_score=cross_trade()\n",
    "\n",
    "print('   [[',winner,winning_score,'%',']]')\n",
    "print('                                          Strategy[cross] avg',cross_avg/4,'%') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2ca9d",
   "metadata": {},
   "source": [
    "### 7.3 Overall Average ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Master_AVG:',((change_buy_sell_avg/4)+(cross_avg/4))/2,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
